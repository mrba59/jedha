{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d964111-98ad-4d24-9557-930aa7c2ef25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier ,AdaBoostClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, ConfusionMatrixDisplay, RocCurveDisplay, classification_report, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e6ffae-6cab-4163-aef7-3cc0e11e1c81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speed</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>diff_angle</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.194243</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>possession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.194267</td>\n",
       "      <td>2.418586e-05</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>possession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194287</td>\n",
       "      <td>1.982327e-05</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>possession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.194301</td>\n",
       "      <td>1.394635e-05</td>\n",
       "      <td>-0.001830</td>\n",
       "      <td>possession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.345452</td>\n",
       "      <td>1.511515e-01</td>\n",
       "      <td>-2.340496</td>\n",
       "      <td>start passe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>0.109933</td>\n",
       "      <td>7.459508e-02</td>\n",
       "      <td>-14.974484</td>\n",
       "      <td>possession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>0.109928</td>\n",
       "      <td>-5.771449e-06</td>\n",
       "      <td>-0.000855</td>\n",
       "      <td>possession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>0.109935</td>\n",
       "      <td>7.432516e-06</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>possession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>0.109947</td>\n",
       "      <td>1.207908e-05</td>\n",
       "      <td>-0.003087</td>\n",
       "      <td>possession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>0.109947</td>\n",
       "      <td>-2.733364e-07</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>possession</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2596 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         speed  acceleration  diff_angle        label\n",
       "0     0.194243  0.000000e+00    0.000000   possession\n",
       "1     0.194267  2.418586e-05    0.000062   possession\n",
       "2     0.194287  1.982327e-05    0.000782   possession\n",
       "3     0.194301  1.394635e-05   -0.001830   possession\n",
       "4     0.345452  1.511515e-01   -2.340496  start passe\n",
       "...        ...           ...         ...          ...\n",
       "2591  0.109933  7.459508e-02  -14.974484   possession\n",
       "2592  0.109928 -5.771449e-06   -0.000855   possession\n",
       "2593  0.109935  7.432516e-06    0.005435   possession\n",
       "2594  0.109947  1.207908e-05   -0.003087   possession\n",
       "2595  0.109947 -2.733364e-07    0.000501   possession\n",
       "\n",
       "[2596 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('/home/reda/Documents/jedha/soccer-tracking/dataset_passe.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef294386-bd8b-4613-bced-da4742ffb7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e678216c-361e-4191-8c4f-ac668f62fd68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "Y_train = labelencoder.fit_transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db2ff4-bee8-4384-a07a-8072b12e5fad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a4e304-0bef-4e5c-9d6d-9cd31de4f6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393168ea-a596-4798-b26f-178ff67507c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75db52-e586-438d-a1a6-d962f1ab95f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e7b7a39-1f50-41ba-a53c-c8425ce79588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df_train[[\"age\",\"total_pages_visited\",\"country\",\"new_user\",\"source\"]]\n",
    "Y = df_train[\"converted\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "965cb451-a0d0-4a07-bcfa-25347b4c5987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X_train= df_train[[\"age\",\"total_pages_visited\",\"country\",\"new_user\",\"source\"]]\n",
    "#X_test= df_test[[\"age\",\"total_pages_visited\",\"country\",\"new_user\",\"source\"]]\n",
    "#Y_train = df_train[\"converted\"]\n",
    "#Y_test = df_test[\"converted\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de04e033-776d-4c3a-bb28-43936540cde6",
   "metadata": {},
   "source": [
    "### Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28fcecc-2868-440e-b3eb-01e12376d2f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_features = [\"age\",\"total_pages_visited\"] # Names of numeric columns in X_train/X_test\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # missing values will be replaced by columns' median\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_features = [\"country\",\"new_user\",\"source\"] # Names of categorical columns in X_train/X_test\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # missing values will be replaced by most frequent value\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f134c-5b61-47b2-9f93-6ff1faa5e766",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2abfe796-1f5b-4d5e-a450-a2df3772eb09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9416098578021411\n",
      "0.9413069887453189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     82620\n",
      "           1       0.35      0.94      0.51      2754\n",
      "\n",
      "    accuracy                           0.94     85374\n",
      "   macro avg       0.67      0.94      0.74     85374\n",
      "weighted avg       0.98      0.94      0.95     85374\n",
      "\n",
      "0.9415395787944808\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced', penalty='l2')\n",
    "model.fit(X_train,Y_train)\n",
    "print(model.score(X_test,Y_test))\n",
    "print(model.score(X_train,Y_train))\n",
    "print(classification_report(y_true = Y_test, y_pred=model.predict(X_test)))\n",
    "print(recall_score(y_true = Y_test, y_pred=model.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c5e84ba-3e37-45fd-8bac-608231593fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done.\n",
      "Best hyperparameters :  {'C': 0.1, 'class_weight': {0: 1, 1: 2}, 'solver': 'liblinear'}\n",
      "Best validation accuracy :  0.8811261214019636\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2')\n",
    "params = {\n",
    "    'solver' : ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag' ,'saga'],\n",
    "    'C': [1e-2, 1e-1, 1,5,10,20,30],\n",
    "    'class_weight': [{0:1,1:5}, {0:1,1:2}, {0:1,1:3},None]\n",
    "}\n",
    "gridsearch = GridSearchCV(model, param_grid = params, cv = 10, n_jobs=-1, scoring='f1_macro') # cv : the number of folds to be used for CV\n",
    "gridsearch.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
    "print(\"Best validation accuracy : \", gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7874f44-1962-4bfa-8037-3c9534b8d0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9850071450324455\n",
      "0.9853167073280925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     82620\n",
      "           1       0.77      0.76      0.77      2754\n",
      "\n",
      "    accuracy                           0.99     85374\n",
      "   macro avg       0.88      0.88      0.88     85374\n",
      "weighted avg       0.98      0.99      0.98     85374\n",
      "\n",
      "0.7585330428467684\n"
     ]
    }
   ],
   "source": [
    "best_LogR = LogisticRegression(class_weight={0:1,1:2}, penalty='l2', solver= 'liblinear', C=0.1)\n",
    "best_LogR.fit(X_train,Y_train)\n",
    "print(best_LogR.score(X_test,Y_test))\n",
    "print(best_LogR.score(X_train,Y_train))\n",
    "print(classification_report(y_true = Y_test, y_pred=best_LogR.predict(X_test)))\n",
    "print(recall_score(y_true = Y_test, y_pred=best_LogR.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6223af38-9f78-4d8f-b9d2-a320cc9c5347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9858504931243705\n",
      "0.9863257130809313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     82620\n",
      "           1       0.85      0.68      0.76      2754\n",
      "\n",
      "    accuracy                           0.99     85374\n",
      "   macro avg       0.92      0.84      0.87     85374\n",
      "weighted avg       0.98      0.99      0.99     85374\n",
      "\n",
      "0.681917211328976\n"
     ]
    }
   ],
   "source": [
    "best_LogR = LogisticRegression(class_weight=None, penalty='l2', solver= 'saga', C=0.1)\n",
    "best_LogR.fit(X_train,Y_train)\n",
    "print(best_LogR.score(X_test,Y_test))\n",
    "print(best_LogR.score(X_train,Y_train))\n",
    "print(classification_report(y_true = Y_test, y_pred=best_LogR.predict(X_test)))\n",
    "print(recall_score(y_true = Y_test, y_pred=best_LogR.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dd2683e-b90f-4d9f-ba61-acd8df207c05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>country</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>UK</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284575</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284576</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284577</th>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284578</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284579</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>Ads</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284580 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  total_pages_visited  country  new_user  source\n",
       "0        22                    2    China         1  Direct\n",
       "1        21                    3       UK         1     Ads\n",
       "2        20                   14  Germany         0     Seo\n",
       "3        23                    3       US         1     Seo\n",
       "4        28                    3       US         1  Direct\n",
       "...     ...                  ...      ...       ...     ...\n",
       "284575   36                    1       US         1     Ads\n",
       "284576   31                    2       US         1     Seo\n",
       "284577   41                    5       US         1     Seo\n",
       "284578   31                    4       US         1  Direct\n",
       "284579   26                    3       US         0     Ads\n",
       "\n",
       "[284580 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79a93b62-480b-469a-99c3-5845a4bce3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model-2\n",
    "best_LogR = LogisticRegression(class_weight='balanced', penalty='l2', solver= 'saga', C=0.1)\n",
    "X_proc = preprocessor.fit_transform(df_train[[\"age\",\"total_pages_visited\",\"country\",\"new_user\",\"source\"]])\n",
    "best_LogR.fit(X_proc,Y)\n",
    "X_test_comp = preprocessor.transform(df_test)\n",
    "Y_test_comp =best_LogR.predict(X_test_comp)\n",
    "df_test_pred = pd.DataFrame(data=Y_test_comp, columns=['converted'])\n",
    "df_test_pred.to_csv('conversion_data_test_predictions_REDA-model2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c14da32-a98b-425e-98b1-052743605f82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model-2nobalance\n",
    "best_LogR = LogisticRegression(penalty='l2', solver= 'saga', C=0.1)\n",
    "X_proc = preprocessor.fit_transform(df_train[[\"age\",\"total_pages_visited\",\"country\",\"new_user\",\"source\"]])\n",
    "best_LogR.fit(X_proc,Y)\n",
    "X_test_comp = preprocessor.transform(df_test)\n",
    "Y_test_comp =best_LogR.predict(X_test_comp)\n",
    "df_test_pred = pd.DataFrame(data=Y_test_comp, columns=['converted'])\n",
    "df_test_pred.to_csv('conversion_data_test_predictions_REDA-model2nobalance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39b970e8-fe56-413f-8357-302ec06e83ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model-2custombalance\n",
    "best_LogR = LogisticRegression(class_weight={0:1,1:2}, penalty='l2', solver= 'liblinear', C=0.1)\n",
    "X_proc = preprocessor.fit_transform(df_train[[\"age\",\"total_pages_visited\",\"country\",\"new_user\",\"source\"]])\n",
    "best_LogR.fit(X_proc,Y)\n",
    "X_test_comp = preprocessor.transform(df_test)\n",
    "Y_test_comp =best_LogR.predict(X_test_comp)\n",
    "df_test_pred = pd.DataFrame(data=Y_test_comp, columns=['converted'])\n",
    "df_test_pred.to_csv('conversion_data_test_predictions_REDA-model2custombalance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d421e2f-b43f-4208-8331-ae14ddc2f17d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 42 candidates, totalling 420 fits\n",
      "...Done.\n",
      "Best hyperparameters :  {'C': 1, 'solver': 'lbfgs'}\n",
      "Best validation accuracy :  0.9863608563061039\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2')\n",
    "params = {\n",
    "    'solver' : ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag' ,'saga'],\n",
    "    'C': [1e-2, 1e-1, 1,5,10,20,30]\n",
    "}\n",
    "gridsearch = GridSearchCV(model, param_grid = params, cv = 10, n_jobs=-1, verbose=3) # cv : the number of folds to be used for CV\n",
    "gridsearch.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
    "print(\"Best validation accuracy : \", gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a600ecaf-70e1-43f0-ba73-fcab2211dd03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9859207721320308\n",
      "0.9863759123721173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     82620\n",
      "           1       0.85      0.69      0.76      2754\n",
      "\n",
      "    accuracy                           0.99     85374\n",
      "   macro avg       0.92      0.84      0.88     85374\n",
      "weighted avg       0.99      0.99      0.99     85374\n",
      "\n",
      "0.6862745098039216\n"
     ]
    }
   ],
   "source": [
    "best_LogR = LogisticRegression( penalty='l2', solver= 'lbfgs', C=1)\n",
    "best_LogR.fit(X_train, Y_train)\n",
    "print(best_LogR.score(X_test,Y_test))\n",
    "print(best_LogR.score(X_train,Y_train))\n",
    "print(classification_report(y_true = Y_test, y_pred=best_LogR.predict(X_test)))\n",
    "print(recall_score(y_true = Y_test, y_pred=best_LogR.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fbb948c-b15d-45c0-8903-76775a4accd6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END alpha=0.01, class_weight=balanced;, score=0.951 total time=   0.2s\n",
      "[CV 7/10] END .alpha=0.1, class_weight=balanced;, score=0.955 total time=   0.1s\n",
      "[CV 4/10] END ..alpha=0.0001, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 10/10] END ..alpha=1e-10, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 8/10] END .............C=0.01, solver=lbfgs;, score=0.987 total time=   0.6s\n",
      "[CV 2/10] END ...............C=0.01, solver=sag;, score=0.986 total time=   1.8s\n",
      "[CV 8/10] END ..........C=0.1, solver=newton-cg;, score=0.987 total time=   1.8s\n",
      "[CV 2/10] END ............C=1, solver=newton-cg;, score=0.986 total time=   1.8s\n",
      "[CV 3/10] END ................C=5, solver=lbfgs;, score=0.986 total time=   0.3s\n",
      "[CV 1/10] END ............C=5, solver=liblinear;, score=0.985 total time=   1.2s\n",
      "[CV 9/10] END ............C=5, solver=newton-cg;, score=0.986 total time=   1.5s\n",
      "[CV 1/10] END ...............C=10, solver=lbfgs;, score=0.985 total time=   0.4s\n",
      "[CV 6/10] END ...............C=10, solver=lbfgs;, score=0.987 total time=   0.4s\n",
      "[CV 3/10] END ...........C=10, solver=liblinear;, score=0.986 total time=   1.6s\n",
      "[CV 1/10] END ................C=10, solver=saga;, score=0.985 total time=   5.0s\n",
      "[CV 1/10] END ...........C=30, solver=newton-cg;, score=0.985 total time=   2.0s\n",
      "[CV 8/10] END ....alpha=0.01, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 4/10] END ...alpha=0.001, class_weight=None;, score=0.970 total time=   0.1s\n",
      "[CV 1/10] END alpha=0.0001, class_weight=balanced;, score=0.950 total time=   0.2s\n",
      "[CV 2/10] END alpha=1e-11, class_weight=balanced;, score=0.951 total time=   0.1s\n",
      "[CV 8/10] END .........C=0.01, solver=liblinear;, score=0.986 total time=   1.2s\n",
      "[CV 2/10] END ..............C=0.1, solver=lbfgs;, score=0.986 total time=   0.4s\n",
      "[CV 4/10] END ..........C=0.1, solver=liblinear;, score=0.986 total time=   1.2s\n",
      "[CV 6/10] END ................C=0.1, solver=sag;, score=0.987 total time=   2.3s\n",
      "[CV 7/10] END ......C=1, solver=newton-cholesky;, score=0.987 total time=   0.4s\n",
      "[CV 2/10] END .................C=1, solver=saga;, score=0.986 total time=   4.2s\n",
      "[CV 7/10] END ...........C=10, solver=liblinear;, score=0.987 total time=   1.5s\n",
      "[CV 8/10] END .................C=10, solver=sag;, score=0.987 total time=   2.0s\n",
      "[CV 6/10] END ...........C=20, solver=newton-cg;, score=0.987 total time=   1.8s\n",
      "[CV 2/10] END ...............C=30, solver=lbfgs;, score=0.986 total time=   0.3s\n",
      "[CV 4/10] END ...............C=30, solver=lbfgs;, score=0.985 total time=   0.3s\n",
      "[CV 7/10] END ...............C=30, solver=lbfgs;, score=0.987 total time=   0.3s\n",
      "[CV 10/10] END ..............C=30, solver=lbfgs;, score=0.986 total time=   0.4s\n",
      "[CV 6/10] END ...........C=30, solver=newton-cg;, score=0.987 total time=   1.8s\n",
      "[CV 1/10] END ....alpha=0.01, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 3/10] END .alpha=0.1, class_weight=balanced;, score=0.950 total time=   0.1s\n",
      "[CV 4/10] END .alpha=0.1, class_weight=balanced;, score=0.952 total time=   0.1s\n",
      "[CV 5/10] END .alpha=0.1, class_weight=balanced;, score=0.951 total time=   0.1s\n",
      "[CV 6/10] END .alpha=0.1, class_weight=balanced;, score=0.954 total time=   0.1s\n",
      "[CV 9/10] END .alpha=0.1, class_weight=balanced;, score=0.949 total time=   0.1s\n",
      "[CV 10/10] END ..alpha=0.001, class_weight=None;, score=0.970 total time=   0.1s\n",
      "[CV 3/10] END alpha=0.0001, class_weight=balanced;, score=0.950 total time=   0.1s\n",
      "[CV 1/10] END alpha=1e-10, class_weight=balanced;, score=0.950 total time=   0.2s\n",
      "[CV 4/10] END .........C=0.01, solver=liblinear;, score=0.985 total time=   1.2s\n",
      "[CV 1/10] END ..............C=0.1, solver=lbfgs;, score=0.985 total time=   0.5s\n",
      "[CV 5/10] END ..........C=0.1, solver=liblinear;, score=0.987 total time=   1.1s\n",
      "[CV 4/10] END ................C=0.1, solver=sag;, score=0.985 total time=   2.3s\n",
      "[CV 4/10] END ......C=1, solver=newton-cholesky;, score=0.985 total time=   0.4s\n",
      "[CV 7/10] END ..................C=1, solver=sag;, score=0.987 total time=   2.8s\n",
      "[CV 6/10] END .................C=5, solver=saga;, score=0.987 total time=   5.0s\n",
      "[CV 9/10] END ...........C=20, solver=newton-cg;, score=0.986 total time=   1.4s\n",
      "[CV 8/10] END ................C=20, solver=saga;, score=0.987 total time=   3.7s\n",
      "[CV 6/10] END alpha=0.01, class_weight=balanced;, score=0.954 total time=   0.2s\n",
      "[CV 7/10] END ...alpha=0.001, class_weight=None;, score=0.969 total time=   0.1s\n",
      "[CV 7/10] END alpha=0.0001, class_weight=balanced;, score=0.955 total time=   0.1s\n",
      "[CV 9/10] END alpha=1e-10, class_weight=balanced;, score=0.949 total time=   0.1s\n",
      "[CV 6/10] END .............C=0.01, solver=lbfgs;, score=0.986 total time=   0.3s\n",
      "[CV 5/10] END ...C=0.01, solver=newton-cholesky;, score=0.987 total time=   0.4s\n",
      "[CV 7/10] END ...............C=0.01, solver=sag;, score=0.987 total time=   1.9s\n",
      "[CV 4/10] END ....C=0.1, solver=newton-cholesky;, score=0.985 total time=   0.3s\n",
      "[CV 9/10] END ................C=0.1, solver=sag;, score=0.986 total time=   2.7s\n",
      "[CV 3/10] END .................C=1, solver=saga;, score=0.986 total time=   4.1s\n",
      "[CV 4/10] END ...........C=10, solver=liblinear;, score=0.985 total time=   0.6s\n",
      "[CV 1/10] END .....C=10, solver=newton-cholesky;, score=0.985 total time=   0.3s\n",
      "[CV 4/10] END .....C=10, solver=newton-cholesky;, score=0.985 total time=   0.3s\n",
      "[CV 9/10] END .....C=10, solver=newton-cholesky;, score=0.986 total time=   0.3s\n",
      "[CV 10/10] END ................C=10, solver=sag;, score=0.986 total time=   2.0s\n",
      "[CV 4/10] END ...........C=20, solver=newton-cg;, score=0.985 total time=   1.5s\n",
      "[CV 9/10] END ................C=20, solver=saga;, score=0.986 total time=   4.2s\n",
      "[CV 4/10] END .....alpha=0.1, class_weight=None;, score=0.970 total time=   0.3s\n",
      "[CV 8/10] END ...alpha=1e-11, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 1/10] END ...C=0.01, solver=newton-cholesky;, score=0.985 total time=   0.5s\n",
      "[CV 3/10] END ...............C=0.01, solver=sag;, score=0.986 total time=   1.8s\n",
      "[CV 9/10] END ..........C=0.1, solver=newton-cg;, score=0.986 total time=   1.7s\n",
      "[CV 1/10] END ............C=1, solver=newton-cg;, score=0.985 total time=   1.7s\n",
      "[CV 9/10] END .................C=1, solver=saga;, score=0.986 total time=   4.0s\n",
      "[CV 6/10] END ...........C=10, solver=liblinear;, score=0.987 total time=   1.5s\n",
      "[CV 7/10] END .................C=10, solver=sag;, score=0.987 total time=   1.9s\n",
      "[CV 9/10] END ...........C=20, solver=liblinear;, score=0.986 total time=   1.5s\n",
      "[CV 3/10] END ................C=20, solver=saga;, score=0.986 total time=   4.4s\n",
      "[CV 7/10] END ....alpha=0.01, class_weight=None;, score=0.969 total time=   0.2s\n",
      "[CV 2/10] END ..alpha=0.0001, class_weight=None;, score=0.969 total time=   0.2s\n",
      "[CV 8/10] END ...alpha=1e-10, class_weight=None;, score=0.970 total time=   0.1s\n",
      "[CV 5/10] END alpha=1e-11, class_weight=balanced;, score=0.951 total time=   0.1s\n",
      "[CV 5/10] END .........C=0.01, solver=liblinear;, score=0.986 total time=   1.2s\n",
      "[CV 10/10] END .............C=0.01, solver=saga;, score=0.985 total time=   1.5s\n",
      "[CV 9/10] END ....C=0.1, solver=newton-cholesky;, score=0.986 total time=   0.4s\n",
      "[CV 2/10] END ................C=1, solver=lbfgs;, score=0.986 total time=   0.5s\n",
      "[CV 5/10] END ............C=1, solver=liblinear;, score=0.987 total time=   1.1s\n",
      "[CV 10/10] END ...........C=1, solver=newton-cg;, score=0.986 total time=   1.5s\n",
      "[CV 9/10] END ................C=5, solver=lbfgs;, score=0.986 total time=   0.5s\n",
      "[CV 1/10] END ............C=5, solver=newton-cg;, score=0.985 total time=   1.6s\n",
      "[CV 4/10] END .................C=5, solver=saga;, score=0.985 total time=   4.5s\n",
      "[CV 2/10] END ...........C=20, solver=liblinear;, score=0.986 total time=   1.4s\n",
      "[CV 10/10] END ....C=20, solver=newton-cholesky;, score=0.986 total time=   0.4s\n",
      "[CV 4/10] END ................C=20, solver=saga;, score=0.985 total time=   4.4s\n",
      "[CV 8/10] END .....alpha=0.1, class_weight=None;, score=0.970 total time=   0.1s\n",
      "[CV 1/10] END alpha=0.001, class_weight=balanced;, score=0.950 total time=   0.1s\n",
      "[CV 6/10] END alpha=0.0001, class_weight=balanced;, score=0.954 total time=   0.2s\n",
      "[CV 5/10] END ...alpha=1e-11, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 10/10] END ........C=0.01, solver=newton-cg;, score=0.985 total time=   1.2s\n",
      "[CV 7/10] END ..............C=0.1, solver=lbfgs;, score=0.987 total time=   0.3s\n",
      "[CV 10/10] END .............C=0.1, solver=lbfgs;, score=0.986 total time=   0.3s\n",
      "[CV 2/10] END ..........C=0.1, solver=newton-cg;, score=0.986 total time=   0.8s\n",
      "[CV 6/10] END ....C=0.1, solver=newton-cholesky;, score=0.987 total time=   0.3s\n",
      "[CV 10/10] END ...............C=0.1, solver=sag;, score=0.986 total time=   2.6s\n",
      "[CV 9/10] END ..................C=1, solver=sag;, score=0.986 total time=   2.9s\n",
      "[CV 9/10] END .................C=5, solver=saga;, score=0.986 total time=   4.3s\n",
      "[CV 1/10] END ...........C=20, solver=liblinear;, score=0.985 total time=   1.3s\n",
      "[CV 8/10] END .....C=20, solver=newton-cholesky;, score=0.987 total time=   0.5s\n",
      "[CV 1/10] END ................C=20, solver=saga;, score=0.985 total time=   4.5s\n",
      "[CV 10/10] END alpha=0.01, class_weight=balanced;, score=0.952 total time=   0.2s\n",
      "[CV 1/10] END ...alpha=0.001, class_weight=None;, score=0.970 total time=   0.0s\n",
      "[CV 5/10] END ..alpha=0.0001, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 4/10] END alpha=1e-10, class_weight=balanced;, score=0.952 total time=   0.2s\n",
      "[CV 10/10] END ........C=0.01, solver=liblinear;, score=0.985 total time=   1.3s\n",
      "[CV 5/10] END ..............C=0.1, solver=lbfgs;, score=0.987 total time=   0.3s\n",
      "[CV 2/10] END ..........C=0.1, solver=liblinear;, score=0.986 total time=   0.5s\n",
      "[CV 3/10] END ..........C=0.1, solver=newton-cg;, score=0.986 total time=   1.1s\n",
      "[CV 5/10] END ................C=1, solver=lbfgs;, score=0.987 total time=   0.3s\n",
      "[CV 10/10] END ...............C=1, solver=lbfgs;, score=0.986 total time=   0.3s\n",
      "[CV 9/10] END ............C=1, solver=liblinear;, score=0.986 total time=   0.6s\n",
      "[CV 7/10] END ............C=1, solver=newton-cg;, score=0.987 total time=   1.1s\n",
      "[CV 1/10] END .................C=1, solver=saga;, score=0.985 total time=   4.6s\n",
      "[CV 7/10] END ...........C=10, solver=newton-cg;, score=0.987 total time=   1.4s\n",
      "[CV 7/10] END ................C=10, solver=saga;, score=0.987 total time=   5.7s\n",
      "[CV 7/10] END .....C=30, solver=newton-cholesky;, score=0.987 total time=   0.3s\n",
      "[CV 3/10] END .................C=30, solver=sag;, score=0.986 total time=   1.6s\n",
      "[CV 7/10] END .....alpha=0.1, class_weight=None;, score=0.969 total time=   0.1s\n",
      "[CV 7/10] END alpha=0.001, class_weight=balanced;, score=0.955 total time=   0.1s\n",
      "[CV 3/10] END ...alpha=1e-10, class_weight=None;, score=0.969 total time=   0.1s\n",
      "[CV 4/10] END ...alpha=1e-11, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 8/10] END .........C=0.01, solver=newton-cg;, score=0.987 total time=   1.2s\n",
      "[CV 4/10] END ..............C=0.1, solver=lbfgs;, score=0.985 total time=   0.3s\n",
      "[CV 9/10] END ..............C=0.1, solver=lbfgs;, score=0.986 total time=   0.2s\n",
      "[CV 9/10] END ..........C=0.1, solver=liblinear;, score=0.986 total time=   0.5s\n",
      "[CV 7/10] END ..........C=0.1, solver=newton-cg;, score=0.987 total time=   1.1s\n",
      "[CV 8/10] END ................C=1, solver=lbfgs;, score=0.987 total time=   0.4s\n",
      "[CV 8/10] END ............C=1, solver=liblinear;, score=0.987 total time=   0.9s\n",
      "[CV 9/10] END ............C=1, solver=newton-cg;, score=0.986 total time=   1.2s\n",
      "[CV 1/10] END ................C=5, solver=lbfgs;, score=0.985 total time=   0.2s\n",
      "[CV 7/10] END ................C=5, solver=lbfgs;, score=0.987 total time=   0.3s\n",
      "[CV 6/10] END ............C=5, solver=liblinear;, score=0.987 total time=   0.7s\n",
      "[CV 8/10] END ............C=5, solver=newton-cg;, score=0.987 total time=   1.1s\n",
      "[CV 8/10] END ..................C=5, solver=sag;, score=0.987 total time=   2.7s\n",
      "[CV 8/10] END .....C=10, solver=newton-cholesky;, score=0.987 total time=   0.3s\n",
      "[CV 4/10] END .................C=10, solver=sag;, score=0.985 total time=   2.1s\n",
      "[CV 8/10] END ...........C=20, solver=newton-cg;, score=0.987 total time=   1.5s\n",
      "[CV 10/10] END ...............C=20, solver=saga;, score=0.986 total time=   4.4s\n",
      "[CV 5/10] END .....alpha=0.1, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 9/10] END ...alpha=0.001, class_weight=None;, score=0.970 total time=   0.1s\n",
      "[CV 9/10] END ..alpha=0.0001, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 10/10] END alpha=1e-10, class_weight=balanced;, score=0.952 total time=   0.2s\n",
      "[CV 2/10] END .........C=0.01, solver=newton-cg;, score=0.986 total time=   1.8s\n",
      "[CV 1/10] END ..........C=0.1, solver=newton-cg;, score=0.985 total time=   1.2s\n",
      "[CV 5/10] END ...............C=0.1, solver=saga;, score=0.987 total time=   3.4s\n",
      "[CV 8/10] END ............C=5, solver=liblinear;, score=0.987 total time=   0.6s\n",
      "[CV 7/10] END ............C=5, solver=newton-cg;, score=0.987 total time=   1.0s\n",
      "[CV 9/10] END ......C=5, solver=newton-cholesky;, score=0.986 total time=   0.2s\n",
      "[CV 10/10] END .................C=5, solver=sag;, score=0.986 total time=   2.0s\n",
      "[CV 8/10] END ...........C=10, solver=newton-cg;, score=0.987 total time=   1.2s\n",
      "[CV 4/10] END ................C=10, solver=saga;, score=0.985 total time=   4.7s\n",
      "[CV 1/10] END ...........C=30, solver=liblinear;, score=0.985 total time=   1.4s\n",
      "[CV 2/10] END .................C=30, solver=sag;, score=0.986 total time=   1.7s\n",
      "[CV 9/10] END alpha=0.01, class_weight=balanced;, score=0.949 total time=   0.2s\n",
      "[CV 3/10] END alpha=0.001, class_weight=balanced;, score=0.950 total time=   0.1s\n",
      "[CV 1/10] END ...alpha=1e-10, class_weight=None;, score=0.970 total time=   0.1s\n",
      "[CV 7/10] END alpha=1e-10, class_weight=balanced;, score=0.955 total time=   0.1s\n",
      "[CV 3/10] END .............C=0.01, solver=lbfgs;, score=0.986 total time=   0.4s\n",
      "[CV 8/10] END ...C=0.01, solver=newton-cholesky;, score=0.987 total time=   0.3s\n",
      "[CV 10/10] END ..............C=0.01, solver=sag;, score=0.985 total time=   1.8s\n",
      "[CV 3/10] END ....C=0.1, solver=newton-cholesky;, score=0.986 total time=   0.4s\n",
      "[CV 3/10] END ...............C=0.1, solver=saga;, score=0.986 total time=   3.2s\n",
      "[CV 8/10] END ................C=5, solver=lbfgs;, score=0.987 total time=   0.5s\n",
      "[CV 10/10] END ...........C=5, solver=liblinear;, score=0.986 total time=   1.5s\n",
      "[CV 4/10] END ..................C=5, solver=sag;, score=0.985 total time=   1.9s\n",
      "[CV 3/10] END ...........C=10, solver=newton-cg;, score=0.986 total time=   1.6s\n",
      "[CV 8/10] END ................C=10, solver=saga;, score=0.987 total time=   3.5s\n",
      "[CV 3/10] END ...............C=30, solver=lbfgs;, score=0.986 total time=   0.3s\n",
      "[CV 6/10] END ...............C=30, solver=lbfgs;, score=0.987 total time=   0.4s\n",
      "[CV 9/10] END ...............C=30, solver=lbfgs;, score=0.986 total time=   0.4s\n",
      "[CV 7/10] END ...........C=30, solver=liblinear;, score=0.987 total time=   1.5s\n",
      "[CV 10/10] END ................C=30, solver=sag;, score=0.986 total time=   1.6s\n",
      "[CV 2/10] END ....alpha=0.01, class_weight=None;, score=0.969 total time=   0.2s\n",
      "[CV 4/10] END alpha=0.001, class_weight=balanced;, score=0.952 total time=   0.2s\n",
      "[CV 7/10] END ...alpha=1e-10, class_weight=None;, score=0.969 total time=   0.2s\n",
      "[CV 5/10] END .............C=0.01, solver=lbfgs;, score=0.987 total time=   0.4s\n",
      "[CV 7/10] END ...C=0.01, solver=newton-cholesky;, score=0.987 total time=   0.4s\n",
      "[CV 9/10] END ...............C=0.01, solver=sag;, score=0.985 total time=   2.1s\n",
      "[CV 7/10] END ................C=0.1, solver=sag;, score=0.987 total time=   2.4s\n",
      "[CV 8/10] END ......C=1, solver=newton-cholesky;, score=0.987 total time=   0.4s\n",
      "[CV 4/10] END .................C=1, solver=saga;, score=0.985 total time=   4.1s\n",
      "[CV 1/10] END ...........C=10, solver=liblinear;, score=0.985 total time=   1.4s\n",
      "[CV 3/10] END .................C=10, solver=sag;, score=0.986 total time=   2.1s\n",
      "[CV 5/10] END ...........C=20, solver=newton-cg;, score=0.987 total time=   1.8s\n",
      "[CV 1/10] END ...............C=30, solver=lbfgs;, score=0.985 total time=   0.4s\n",
      "[CV 5/10] END ...............C=30, solver=lbfgs;, score=0.987 total time=   0.4s\n",
      "[CV 8/10] END ...............C=30, solver=lbfgs;, score=0.987 total time=   0.4s\n",
      "[CV 5/10] END ...........C=30, solver=liblinear;, score=0.987 total time=   1.4s\n",
      "[CV 6/10] END .................C=30, solver=sag;, score=0.987 total time=   1.7s\n",
      "[CV 6/10] END .....alpha=0.1, class_weight=None;, score=0.969 total time=   0.3s\n",
      "[CV 6/10] END ...alpha=1e-11, class_weight=None;, score=0.969 total time=   0.2s\n",
      "[CV 9/10] END .........C=0.01, solver=newton-cg;, score=0.985 total time=   1.2s\n",
      "[CV 6/10] END ..............C=0.1, solver=lbfgs;, score=0.987 total time=   0.4s\n",
      "[CV 6/10] END ..........C=0.1, solver=liblinear;, score=0.987 total time=   0.9s\n",
      "[CV 5/10] END ....C=0.1, solver=newton-cholesky;, score=0.987 total time=   0.3s\n",
      "[CV 2/10] END ...............C=0.1, solver=saga;, score=0.986 total time=   3.4s\n",
      "[CV 4/10] END ............C=5, solver=liblinear;, score=0.985 total time=   0.6s\n",
      "[CV 5/10] END ............C=5, solver=newton-cg;, score=0.987 total time=   1.0s\n",
      "[CV 8/10] END ......C=5, solver=newton-cholesky;, score=0.987 total time=   0.2s\n",
      "[CV 9/10] END ..................C=5, solver=sag;, score=0.986 total time=   1.8s\n",
      "[CV 1/10] END ...........C=10, solver=newton-cg;, score=0.985 total time=   1.1s\n",
      "[CV 1/10] END .................C=10, solver=sag;, score=0.985 total time=   2.1s\n",
      "[CV 2/10] END ...........C=20, solver=newton-cg;, score=0.986 total time=   1.4s\n",
      "[CV 5/10] END ................C=20, solver=saga;, score=0.987 total time=   4.7s\n",
      "[CV 5/10] END ....alpha=0.01, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 8/10] END ...alpha=0.001, class_weight=None;, score=0.970 total time=   0.1s\n",
      "[CV 10/10] END .alpha=0.0001, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 3/10] END ...alpha=1e-11, class_weight=None;, score=0.969 total time=   0.2s\n",
      "[CV 5/10] END .........C=0.01, solver=newton-cg;, score=0.987 total time=   1.7s\n",
      "[CV 8/10] END ..........C=0.1, solver=liblinear;, score=0.987 total time=   1.2s\n",
      "[CV 4/10] END ...............C=0.1, solver=saga;, score=0.985 total time=   3.0s\n",
      "[CV 5/10] END ................C=5, solver=lbfgs;, score=0.987 total time=   0.4s\n",
      "[CV 9/10] END ............C=5, solver=liblinear;, score=0.986 total time=   1.2s\n",
      "[CV 1/10] END ......C=5, solver=newton-cholesky;, score=0.985 total time=   0.4s\n",
      "[CV 10/10] END .....C=5, solver=newton-cholesky;, score=0.986 total time=   0.3s\n",
      "[CV 7/10] END .................C=5, solver=saga;, score=0.987 total time=   4.8s\n",
      "[CV 3/10] END ...........C=20, solver=newton-cg;, score=0.986 total time=   1.4s\n",
      "[CV 6/10] END ................C=20, solver=saga;, score=0.987 total time=   4.7s\n",
      "[CV 1/10] END .alpha=0.1, class_weight=balanced;, score=0.950 total time=   0.2s\n",
      "[CV 10/10] END alpha=1e-11, class_weight=balanced;, score=0.952 total time=   0.1s\n",
      "[CV 7/10] END .........C=0.01, solver=newton-cg;, score=0.987 total time=   1.1s\n",
      "[CV 6/10] END ..............C=0.01, solver=saga;, score=0.986 total time=   1.9s\n",
      "[CV 7/10] END ...............C=0.1, solver=saga;, score=0.987 total time=   3.3s\n",
      "[CV 3/10] END ............C=5, solver=liblinear;, score=0.986 total time=   0.7s\n",
      "[CV 4/10] END ............C=5, solver=newton-cg;, score=0.985 total time=   1.0s\n",
      "[CV 7/10] END ......C=5, solver=newton-cholesky;, score=0.987 total time=   0.2s\n",
      "[CV 6/10] END ..................C=5, solver=sag;, score=0.987 total time=   2.1s\n",
      "[CV 9/10] END ...........C=10, solver=newton-cg;, score=0.986 total time=   1.1s\n",
      "[CV 3/10] END ................C=10, solver=saga;, score=0.986 total time=   4.8s\n",
      "[CV 6/10] END ...........C=30, solver=liblinear;, score=0.987 total time=   0.8s\n",
      "[CV 4/10] END .....C=30, solver=newton-cholesky;, score=0.985 total time=   0.3s\n",
      "[CV 8/10] END .....C=30, solver=newton-cholesky;, score=0.987 total time=   0.3s\n",
      "[CV 7/10] END .................C=30, solver=sag;, score=0.987 total time=   1.7s\n",
      "[CV 1/10] END alpha=0.01, class_weight=balanced;, score=0.950 total time=   0.3s\n",
      "[CV 10/10] END alpha=0.1, class_weight=balanced;, score=0.952 total time=   0.1s\n",
      "[CV 8/10] END ..alpha=0.0001, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 8/10] END alpha=1e-10, class_weight=balanced;, score=0.948 total time=   0.2s\n",
      "[CV 1/10] END .........C=0.01, solver=newton-cg;, score=0.985 total time=   1.7s\n",
      "[CV 7/10] END ..........C=0.1, solver=liblinear;, score=0.987 total time=   1.1s\n",
      "[CV 3/10] END ................C=0.1, solver=sag;, score=0.986 total time=   2.1s\n",
      "[CV 1/10] END ......C=1, solver=newton-cholesky;, score=0.985 total time=   0.4s\n",
      "[CV 9/10] END ......C=1, solver=newton-cholesky;, score=0.986 total time=   0.4s\n",
      "[CV 5/10] END .................C=1, solver=saga;, score=0.987 total time=   4.1s\n",
      "[CV 2/10] END ...........C=10, solver=liblinear;, score=0.986 total time=   1.5s\n",
      "[CV 5/10] END .................C=10, solver=sag;, score=0.987 total time=   1.9s\n",
      "[CV 10/10] END ..........C=20, solver=liblinear;, score=0.986 total time=   1.5s\n",
      "[CV 2/10] END ................C=20, solver=saga;, score=0.986 total time=   4.8s\n",
      "[CV 9/10] END .....alpha=0.1, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 2/10] END ...alpha=1e-11, class_weight=None;, score=0.969 total time=   0.1s\n",
      "[CV 7/10] END .............C=0.01, solver=lbfgs;, score=0.987 total time=   0.3s\n",
      "[CV 3/10] END ...C=0.01, solver=newton-cholesky;, score=0.986 total time=   0.4s\n",
      "[CV 5/10] END ...............C=0.01, solver=sag;, score=0.987 total time=   1.8s\n",
      "[CV 10/10] END .........C=0.1, solver=newton-cg;, score=0.986 total time=   1.1s\n",
      "[CV 2/10] END ............C=1, solver=liblinear;, score=0.986 total time=   0.8s\n",
      "[CV 5/10] END ............C=1, solver=newton-cg;, score=0.987 total time=   1.3s\n",
      "[CV 7/10] END .................C=1, solver=saga;, score=0.987 total time=   3.9s\n",
      "[CV 8/10] END ...............C=10, solver=lbfgs;, score=0.987 total time=   0.4s\n",
      "[CV 2/10] END ...........C=10, solver=newton-cg;, score=0.986 total time=   1.7s\n",
      "[CV 9/10] END ................C=10, solver=saga;, score=0.986 total time=   4.4s\n",
      "[CV 2/10] END ...........C=30, solver=liblinear;, score=0.986 total time=   1.4s\n",
      "[CV 1/10] END .................C=30, solver=sag;, score=0.985 total time=   1.9s\n",
      "[CV 2/10] END .....alpha=0.1, class_weight=None;, score=0.969 total time=   0.2s\n",
      "[CV 2/10] END ...alpha=0.001, class_weight=None;, score=0.969 total time=   0.1s\n",
      "[CV 7/10] END ..alpha=0.0001, class_weight=None;, score=0.969 total time=   0.1s\n",
      "[CV 6/10] END ...alpha=1e-10, class_weight=None;, score=0.969 total time=   0.1s\n",
      "[CV 6/10] END alpha=1e-11, class_weight=balanced;, score=0.954 total time=   0.1s\n",
      "[CV 7/10] END .........C=0.01, solver=liblinear;, score=0.986 total time=   0.9s\n",
      "[CV 3/10] END ..............C=0.01, solver=saga;, score=0.986 total time=   1.6s\n",
      "[CV 2/10] END ....C=0.1, solver=newton-cholesky;, score=0.986 total time=   0.2s\n",
      "[CV 1/10] END ................C=0.1, solver=sag;, score=0.985 total time=   2.7s\n",
      "[CV 4/10] END ..................C=1, solver=sag;, score=0.985 total time=   2.9s\n",
      "[CV 1/10] END .................C=5, solver=saga;, score=0.985 total time=   4.9s\n",
      "[CV 1/10] END ...........C=20, solver=newton-cg;, score=0.985 total time=   1.3s\n",
      "[CV 7/10] END .................C=20, solver=sag;, score=0.987 total time=   2.1s\n",
      "[CV 1/10] END .....C=30, solver=newton-cholesky;, score=0.985 total time=   0.2s\n",
      "[CV 3/10] END .....C=30, solver=newton-cholesky;, score=0.986 total time=   0.2s\n",
      "[CV 5/10] END .....C=30, solver=newton-cholesky;, score=0.987 total time=   0.2s\n",
      "[CV 9/10] END .....C=30, solver=newton-cholesky;, score=0.986 total time=   0.2s\n",
      "[CV 4/10] END .................C=30, solver=sag;, score=0.985 total time=   1.8s\n",
      "[CV 2/10] END alpha=0.01, class_weight=balanced;, score=0.951 total time=   0.2s\n",
      "[CV 8/10] END .alpha=0.1, class_weight=balanced;, score=0.948 total time=   0.1s\n",
      "[CV 2/10] END alpha=0.001, class_weight=balanced;, score=0.951 total time=   0.1s\n",
      "[CV 5/10] END alpha=0.0001, class_weight=balanced;, score=0.951 total time=   0.2s\n",
      "[CV 7/10] END alpha=1e-11, class_weight=balanced;, score=0.955 total time=   0.1s\n",
      "[CV 6/10] END .........C=0.01, solver=liblinear;, score=0.986 total time=   1.2s\n",
      "[CV 9/10] END ..............C=0.01, solver=saga;, score=0.985 total time=   1.7s\n",
      "[CV 8/10] END ................C=0.1, solver=sag;, score=0.987 total time=   2.2s\n",
      "[CV 5/10] END ......C=1, solver=newton-cholesky;, score=0.987 total time=   0.4s\n",
      "[CV 8/10] END ..................C=1, solver=sag;, score=0.987 total time=   2.4s\n",
      "[CV 6/10] END ......C=5, solver=newton-cholesky;, score=0.987 total time=   0.4s\n",
      "[CV 3/10] END .................C=5, solver=saga;, score=0.986 total time=   4.3s\n",
      "[CV 8/10] END ...............C=20, solver=lbfgs;, score=0.987 total time=   0.4s\n",
      "[CV 4/10] END ...........C=20, solver=liblinear;, score=0.985 total time=   1.1s\n",
      "[CV 6/10] END .....C=20, solver=newton-cholesky;, score=0.987 total time=   0.3s\n",
      "[CV 2/10] END .................C=20, solver=sag;, score=0.986 total time=   2.2s\n",
      "[CV 7/10] END ...........C=30, solver=newton-cg;, score=0.987 total time=   1.0s\n",
      "[CV 5/10] END .................C=30, solver=sag;, score=0.987 total time=   1.8s\n",
      "[CV 10/10] END ...alpha=0.01, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 9/10] END alpha=0.001, class_weight=balanced;, score=0.949 total time=   0.1s\n",
      "[CV 5/10] END ...alpha=1e-10, class_weight=None;, score=0.970 total time=   0.1s\n",
      "[CV 9/10] END alpha=1e-11, class_weight=balanced;, score=0.949 total time=   0.1s\n",
      "[CV 6/10] END .........C=0.01, solver=newton-cg;, score=0.986 total time=   1.3s\n",
      "[CV 8/10] END ..............C=0.1, solver=lbfgs;, score=0.987 total time=   0.2s\n",
      "[CV 1/10] END ..........C=0.1, solver=liblinear;, score=0.985 total time=   0.6s\n",
      "[CV 4/10] END ..........C=0.1, solver=newton-cg;, score=0.985 total time=   1.0s\n",
      "[CV 3/10] END ................C=1, solver=lbfgs;, score=0.986 total time=   0.3s\n",
      "[CV 9/10] END ................C=1, solver=lbfgs;, score=0.986 total time=   0.3s\n",
      "[CV 6/10] END ............C=1, solver=liblinear;, score=0.987 total time=   0.7s\n",
      "[CV 6/10] END ............C=1, solver=newton-cg;, score=0.987 total time=   1.1s\n",
      "[CV 6/10] END ..................C=1, solver=sag;, score=0.987 total time=   2.8s\n",
      "[CV 2/10] END .................C=5, solver=saga;, score=0.986 total time=   4.8s\n",
      "[CV 8/10] END ...........C=20, solver=liblinear;, score=0.987 total time=   0.7s\n",
      "[CV 3/10] END .....C=20, solver=newton-cholesky;, score=0.986 total time=   0.3s\n",
      "[CV 7/10] END .....C=20, solver=newton-cholesky;, score=0.987 total time=   0.3s\n",
      "[CV 4/10] END .................C=20, solver=sag;, score=0.985 total time=   1.8s\n",
      "[CV 4/10] END ...........C=30, solver=liblinear;, score=0.985 total time=   1.5s\n",
      "[CV 9/10] END .................C=30, solver=sag;, score=0.986 total time=   1.8s\n",
      "[CV 1/10] END .....alpha=0.1, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 5/10] END alpha=0.001, class_weight=balanced;, score=0.951 total time=   0.1s\n",
      "[CV 4/10] END ...alpha=1e-10, class_weight=None;, score=0.970 total time=   0.1s\n",
      "[CV 10/10] END ..alpha=1e-11, class_weight=None;, score=0.970 total time=   0.1s\n",
      "[CV 2/10] END ...C=0.01, solver=newton-cholesky;, score=0.986 total time=   0.4s\n",
      "[CV 10/10] END ..C=0.01, solver=newton-cholesky;, score=0.985 total time=   0.3s\n",
      "[CV 2/10] END ..............C=0.01, solver=saga;, score=0.986 total time=   1.7s\n",
      "[CV 1/10] END ....C=0.1, solver=newton-cholesky;, score=0.985 total time=   0.4s\n",
      "[CV 1/10] END ...............C=0.1, solver=saga;, score=0.985 total time=   2.9s\n",
      "[CV 2/10] END ................C=5, solver=lbfgs;, score=0.986 total time=   0.4s\n",
      "[CV 10/10] END ...............C=5, solver=lbfgs;, score=0.986 total time=   0.5s\n",
      "[CV 2/10] END ............C=5, solver=newton-cg;, score=0.986 total time=   1.7s\n",
      "[CV 8/10] END .................C=5, solver=saga;, score=0.987 total time=   3.4s\n",
      "[CV 10/10] END ...............C=10, solver=saga;, score=0.986 total time=   4.8s\n",
      "[CV 9/10] END ...........C=30, solver=newton-cg;, score=0.986 total time=   1.1s\n",
      "[CV 8/10] END .................C=30, solver=sag;, score=0.987 total time=   1.8s\n",
      "[CV 3/10] END ....alpha=0.01, class_weight=None;, score=0.969 total time=   0.2s\n",
      "[CV 8/10] END alpha=0.001, class_weight=balanced;, score=0.948 total time=   0.1s\n",
      "[CV 10/10] END alpha=0.0001, class_weight=balanced;, score=0.952 total time=   0.1s\n",
      "[CV 1/10] END ...alpha=1e-11, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 3/10] END .........C=0.01, solver=newton-cg;, score=0.986 total time=   1.1s\n",
      "[CV 5/10] END ..............C=0.01, solver=saga;, score=0.987 total time=   2.1s\n",
      "[CV 6/10] END ................C=1, solver=lbfgs;, score=0.987 total time=   0.3s\n",
      "[CV 4/10] END ............C=1, solver=liblinear;, score=0.985 total time=   0.6s\n",
      "[CV 3/10] END ............C=1, solver=newton-cg;, score=0.986 total time=   0.9s\n",
      "[CV 6/10] END ......C=1, solver=newton-cholesky;, score=0.987 total time=   0.2s\n",
      "[CV 3/10] END ..................C=1, solver=sag;, score=0.986 total time=   2.9s\n",
      "[CV 5/10] END .................C=5, solver=saga;, score=0.987 total time=   5.1s\n",
      "[CV 10/10] END ..........C=20, solver=newton-cg;, score=0.986 total time=   1.3s\n",
      "[CV 7/10] END ................C=20, solver=saga;, score=0.987 total time=   4.8s\n",
      "[CV 6/10] END ....alpha=0.01, class_weight=None;, score=0.969 total time=   0.2s\n",
      "[CV 6/10] END ..alpha=0.0001, class_weight=None;, score=0.969 total time=   0.2s\n",
      "[CV 5/10] END alpha=1e-10, class_weight=balanced;, score=0.951 total time=   0.1s\n",
      "[CV 2/10] END .............C=0.01, solver=lbfgs;, score=0.986 total time=   0.3s\n",
      "[CV 4/10] END ...C=0.01, solver=newton-cholesky;, score=0.985 total time=   0.4s\n",
      "[CV 6/10] END ...............C=0.01, solver=sag;, score=0.986 total time=   2.5s\n",
      "[CV 4/10] END ................C=1, solver=lbfgs;, score=0.985 total time=   0.3s\n",
      "[CV 1/10] END ............C=1, solver=liblinear;, score=0.985 total time=   0.8s\n",
      "[CV 4/10] END ............C=1, solver=newton-cg;, score=0.985 total time=   1.2s\n",
      "[CV 10/10] END .................C=1, solver=sag;, score=0.986 total time=   2.9s\n",
      "[CV 10/10] END ................C=5, solver=saga;, score=0.986 total time=   4.8s\n",
      "[CV 7/10] END ...........C=20, solver=newton-cg;, score=0.987 total time=   1.2s\n",
      "[CV 8/10] END .................C=20, solver=sag;, score=0.987 total time=   2.1s\n",
      "[CV 10/10] END ..........C=30, solver=newton-cg;, score=0.986 total time=   1.4s\n",
      "[CV 8/10] END ................C=30, solver=saga;, score=0.987 total time=   2.0s\n",
      "[CV 7/10] END alpha=0.01, class_weight=balanced;, score=0.955 total time=   0.2s\n",
      "[CV 6/10] END ...alpha=0.001, class_weight=None;, score=0.969 total time=   0.1s\n",
      "[CV 8/10] END alpha=0.0001, class_weight=balanced;, score=0.948 total time=   0.1s\n",
      "[CV 6/10] END alpha=1e-10, class_weight=balanced;, score=0.954 total time=   0.1s\n",
      "[CV 4/10] END .............C=0.01, solver=lbfgs;, score=0.985 total time=   0.4s\n",
      "[CV 9/10] END ...C=0.01, solver=newton-cholesky;, score=0.985 total time=   0.3s\n",
      "[CV 1/10] END ..............C=0.01, solver=saga;, score=0.985 total time=   2.0s\n",
      "[CV 2/10] END ................C=0.1, solver=sag;, score=0.986 total time=   2.7s\n",
      "[CV 5/10] END ..................C=1, solver=sag;, score=0.987 total time=   2.2s\n",
      "[CV 2/10] END ......C=5, solver=newton-cholesky;, score=0.986 total time=   0.4s\n",
      "[CV 2/10] END ..................C=5, solver=sag;, score=0.986 total time=   1.6s\n",
      "[CV 10/10] END ..............C=10, solver=lbfgs;, score=0.986 total time=   0.5s\n",
      "[CV 6/10] END ...........C=10, solver=newton-cg;, score=0.987 total time=   1.8s\n",
      "[CV 3/10] END ...............C=20, solver=lbfgs;, score=0.986 total time=   0.3s\n",
      "[CV 6/10] END ...............C=20, solver=lbfgs;, score=0.987 total time=   0.4s\n",
      "[CV 10/10] END ..............C=20, solver=lbfgs;, score=0.986 total time=   0.4s\n",
      "[CV 7/10] END ...........C=20, solver=liblinear;, score=0.987 total time=   1.5s\n",
      "[CV 10/10] END ................C=20, solver=sag;, score=0.986 total time=   1.7s\n",
      "[CV 10/10] END ..........C=30, solver=liblinear;, score=0.986 total time=   1.5s\n",
      "[CV 4/10] END ................C=30, solver=saga;, score=0.985 total time=   2.5s\n",
      "[CV 4/10] END alpha=0.01, class_weight=balanced;, score=0.952 total time=   0.2s\n",
      "[CV 5/10] END ...alpha=0.001, class_weight=None;, score=0.970 total time=   0.1s\n",
      "[CV 4/10] END alpha=0.0001, class_weight=balanced;, score=0.952 total time=   0.1s\n",
      "[CV 2/10] END alpha=1e-10, class_weight=balanced;, score=0.951 total time=   0.2s\n",
      "[CV 3/10] END .........C=0.01, solver=liblinear;, score=0.986 total time=   1.1s\n",
      "[CV 4/10] END ..............C=0.01, solver=saga;, score=0.985 total time=   1.6s\n",
      "[CV 8/10] END ....C=0.1, solver=newton-cholesky;, score=0.987 total time=   0.4s\n",
      "[CV 1/10] END ................C=1, solver=lbfgs;, score=0.985 total time=   0.5s\n",
      "[CV 3/10] END ............C=1, solver=liblinear;, score=0.986 total time=   1.3s\n",
      "[CV 2/10] END ......C=1, solver=newton-cholesky;, score=0.986 total time=   0.4s\n",
      "[CV 10/10] END .....C=1, solver=newton-cholesky;, score=0.986 total time=   0.4s\n",
      "[CV 6/10] END .................C=1, solver=saga;, score=0.987 total time=   4.1s\n",
      "[CV 8/10] END ...........C=10, solver=liblinear;, score=0.987 total time=   1.5s\n",
      "[CV 9/10] END .................C=10, solver=sag;, score=0.986 total time=   1.7s\n",
      "[CV 6/10] END ...........C=20, solver=liblinear;, score=0.987 total time=   1.5s\n",
      "[CV 5/10] END .................C=20, solver=sag;, score=0.987 total time=   1.8s\n",
      "[CV 9/10] END ...........C=30, solver=liblinear;, score=0.986 total time=   1.5s\n",
      "[CV 3/10] END ................C=30, solver=saga;, score=0.986 total time=   2.6s\n",
      "[CV 10/10] END ....alpha=0.1, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 1/10] END alpha=1e-11, class_weight=balanced;, score=0.950 total time=   0.1s\n",
      "[CV 10/10] END ............C=0.01, solver=lbfgs;, score=0.985 total time=   0.7s\n",
      "[CV 4/10] END ...............C=0.01, solver=sag;, score=0.985 total time=   1.6s\n",
      "[CV 6/10] END ..........C=0.1, solver=newton-cg;, score=0.987 total time=   1.6s\n",
      "[CV 10/10] END ...........C=1, solver=liblinear;, score=0.986 total time=   1.0s\n",
      "[CV 3/10] END ......C=1, solver=newton-cholesky;, score=0.986 total time=   0.4s\n",
      "[CV 2/10] END ..................C=1, solver=sag;, score=0.986 total time=   2.4s\n",
      "[CV 4/10] END ......C=5, solver=newton-cholesky;, score=0.985 total time=   0.4s\n",
      "[CV 7/10] END ..................C=5, solver=sag;, score=0.987 total time=   1.7s\n",
      "[CV 10/10] END ..........C=10, solver=liblinear;, score=0.986 total time=   1.5s\n",
      "[CV 6/10] END ................C=10, solver=saga;, score=0.987 total time=   4.8s\n",
      "[CV 2/10] END ...........C=30, solver=newton-cg;, score=0.986 total time=   1.9s\n",
      "[CV 10/10] END ...............C=30, solver=saga;, score=0.986 total time=   2.2s\n",
      "[CV 3/10] END .....alpha=0.1, class_weight=None;, score=0.969 total time=   0.2s\n",
      "[CV 10/10] END alpha=0.001, class_weight=balanced;, score=0.952 total time=   0.2s\n",
      "[CV 3/10] END alpha=1e-10, class_weight=balanced;, score=0.950 total time=   0.1s\n",
      "[CV 1/10] END .............C=0.01, solver=lbfgs;, score=0.985 total time=   0.3s\n",
      "[CV 6/10] END ...C=0.01, solver=newton-cholesky;, score=0.986 total time=   0.4s\n",
      "[CV 8/10] END ...............C=0.01, solver=sag;, score=0.987 total time=   2.3s\n",
      "[CV 8/10] END ...............C=0.1, solver=saga;, score=0.987 total time=   2.8s\n",
      "[CV 10/10] END ................C=1, solver=saga;, score=0.986 total time=   5.0s\n",
      "[CV 7/10] END .....C=10, solver=newton-cholesky;, score=0.987 total time=   0.4s\n",
      "[CV 6/10] END .................C=10, solver=sag;, score=0.987 total time=   2.4s\n",
      "[CV 2/10] END .....C=20, solver=newton-cholesky;, score=0.986 total time=   0.3s\n",
      "[CV 5/10] END .....C=20, solver=newton-cholesky;, score=0.987 total time=   0.3s\n",
      "[CV 1/10] END .................C=20, solver=sag;, score=0.985 total time=   2.2s\n",
      "[CV 5/10] END ...........C=30, solver=newton-cg;, score=0.987 total time=   1.4s\n",
      "[CV 7/10] END ................C=30, solver=saga;, score=0.987 total time=   2.6s\n",
      "[CV 8/10] END alpha=0.01, class_weight=balanced;, score=0.948 total time=   0.2s\n",
      "[CV 1/10] END ..alpha=0.0001, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 9/10] END ...alpha=1e-10, class_weight=None;, score=0.970 total time=   0.1s\n",
      "[CV 8/10] END alpha=1e-11, class_weight=balanced;, score=0.948 total time=   0.1s\n",
      "[CV 9/10] END .........C=0.01, solver=liblinear;, score=0.985 total time=   1.2s\n",
      "[CV 3/10] END ..............C=0.1, solver=lbfgs;, score=0.986 total time=   0.4s\n",
      "[CV 3/10] END ..........C=0.1, solver=liblinear;, score=0.986 total time=   1.1s\n",
      "[CV 10/10] END ...C=0.1, solver=newton-cholesky;, score=0.986 total time=   0.3s\n",
      "[CV 6/10] END ...............C=0.1, solver=saga;, score=0.987 total time=   3.1s\n",
      "[CV 6/10] END ................C=5, solver=lbfgs;, score=0.987 total time=   0.3s\n",
      "[CV 7/10] END ............C=5, solver=liblinear;, score=0.987 total time=   0.7s\n",
      "[CV 6/10] END ............C=5, solver=newton-cg;, score=0.987 total time=   1.1s\n",
      "[CV 1/10] END ..................C=5, solver=sag;, score=0.985 total time=   1.8s\n",
      "[CV 9/10] END ...........C=10, solver=liblinear;, score=0.986 total time=   0.7s\n",
      "[CV 3/10] END .....C=10, solver=newton-cholesky;, score=0.986 total time=   0.2s\n",
      "[CV 6/10] END .....C=10, solver=newton-cholesky;, score=0.987 total time=   0.3s\n",
      "[CV 10/10] END ....C=10, solver=newton-cholesky;, score=0.986 total time=   0.2s\n",
      "[CV 2/10] END ................C=10, solver=saga;, score=0.986 total time=   4.8s\n",
      "[CV 3/10] END ...........C=30, solver=liblinear;, score=0.986 total time=   0.7s\n",
      "[CV 2/10] END .....C=30, solver=newton-cholesky;, score=0.986 total time=   0.3s\n",
      "[CV 6/10] END .....C=30, solver=newton-cholesky;, score=0.987 total time=   0.3s\n",
      "[CV 10/10] END ....C=30, solver=newton-cholesky;, score=0.986 total time=   0.3s\n",
      "[CV 1/10] END ................C=30, solver=saga;, score=0.985 total time=   2.8s\n",
      "[CV 9/10] END ....alpha=0.01, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 6/10] END alpha=0.001, class_weight=balanced;, score=0.954 total time=   0.1s\n",
      "[CV 2/10] END ...alpha=1e-10, class_weight=None;, score=0.969 total time=   0.1s\n",
      "[CV 7/10] END ...alpha=1e-11, class_weight=None;, score=0.969 total time=   0.1s\n",
      "[CV 4/10] END .........C=0.01, solver=newton-cg;, score=0.985 total time=   1.8s\n",
      "[CV 10/10] END .........C=0.1, solver=liblinear;, score=0.986 total time=   1.2s\n",
      "[CV 9/10] END ...............C=0.1, solver=saga;, score=0.986 total time=   3.2s\n",
      "[CV 2/10] END ............C=5, solver=liblinear;, score=0.986 total time=   0.6s\n",
      "[CV 3/10] END ............C=5, solver=newton-cg;, score=0.986 total time=   0.9s\n",
      "[CV 5/10] END ......C=5, solver=newton-cholesky;, score=0.987 total time=   0.2s\n",
      "[CV 3/10] END ..................C=5, solver=sag;, score=0.986 total time=   2.2s\n",
      "[CV 10/10] END ..........C=10, solver=newton-cg;, score=0.986 total time=   1.1s\n",
      "[CV 5/10] END ................C=10, solver=saga;, score=0.987 total time=   5.0s\n",
      "[CV 4/10] END ...........C=30, solver=newton-cg;, score=0.985 total time=   1.4s\n",
      "[CV 5/10] END ................C=30, solver=saga;, score=0.987 total time=   2.7s\n",
      "[CV 4/10] END ....alpha=0.01, class_weight=None;, score=0.970 total time=   0.2s\n",
      "[CV 3/10] END ..alpha=0.0001, class_weight=None;, score=0.969 total time=   0.1s\n",
      "[CV 9/10] END alpha=0.0001, class_weight=balanced;, score=0.949 total time=   0.1s\n",
      "[CV 9/10] END ...alpha=1e-11, class_weight=None;, score=0.970 total time=   0.1s\n",
      "[CV 9/10] END .............C=0.01, solver=lbfgs;, score=0.985 total time=   0.6s\n",
      "[CV 1/10] END ...............C=0.01, solver=sag;, score=0.985 total time=   1.6s\n",
      "[CV 5/10] END ..........C=0.1, solver=newton-cg;, score=0.987 total time=   1.2s\n",
      "[CV 7/10] END ................C=1, solver=lbfgs;, score=0.987 total time=   0.3s\n",
      "[CV 7/10] END ............C=1, solver=liblinear;, score=0.987 total time=   0.8s\n",
      "[CV 8/10] END ............C=1, solver=newton-cg;, score=0.987 total time=   1.2s\n",
      "[CV 8/10] END .................C=1, solver=saga;, score=0.987 total time=   3.3s\n",
      "[CV 3/10] END ...............C=10, solver=lbfgs;, score=0.986 total time=   0.2s\n",
      "[CV 4/10] END ...............C=10, solver=lbfgs;, score=0.985 total time=   0.2s\n",
      "[CV 7/10] END ...............C=10, solver=lbfgs;, score=0.987 total time=   0.2s\n",
      "[CV 5/10] END ...........C=10, solver=liblinear;, score=0.987 total time=   0.7s\n",
      "[CV 2/10] END .....C=10, solver=newton-cholesky;, score=0.986 total time=   0.3s\n",
      "[CV 5/10] END .....C=10, solver=newton-cholesky;, score=0.987 total time=   0.3s\n",
      "[CV 2/10] END .................C=10, solver=sag;, score=0.986 total time=   2.4s\n",
      "[CV 1/10] END .....C=20, solver=newton-cholesky;, score=0.985 total time=   0.3s\n",
      "[CV 4/10] END .....C=20, solver=newton-cholesky;, score=0.985 total time=   0.3s\n",
      "[CV 9/10] END .....C=20, solver=newton-cholesky;, score=0.986 total time=   0.4s\n",
      "[CV 9/10] END .................C=20, solver=sag;, score=0.986 total time=   1.8s\n",
      "[CV 3/10] END ...........C=30, solver=newton-cg;, score=0.986 total time=   1.8s\n",
      "[CV 9/10] END ................C=30, solver=saga;, score=0.986 total time=   2.4s\n",
      "[CV 3/10] END alpha=0.01, class_weight=balanced;, score=0.950 total time=   0.2s\n",
      "[CV 3/10] END ...alpha=0.001, class_weight=None;, score=0.969 total time=   0.1s\n",
      "[CV 2/10] END alpha=0.0001, class_weight=balanced;, score=0.951 total time=   0.2s\n",
      "[CV 4/10] END alpha=1e-11, class_weight=balanced;, score=0.952 total time=   0.1s\n",
      "[CV 2/10] END .........C=0.01, solver=liblinear;, score=0.985 total time=   1.2s\n",
      "[CV 8/10] END ..............C=0.01, solver=saga;, score=0.987 total time=   1.6s\n",
      "[CV 5/10] END ................C=0.1, solver=sag;, score=0.987 total time=   2.5s\n",
      "[CV 1/10] END ..................C=1, solver=sag;, score=0.985 total time=   2.4s\n",
      "[CV 3/10] END ......C=5, solver=newton-cholesky;, score=0.986 total time=   0.4s\n",
      "[CV 5/10] END ..................C=5, solver=sag;, score=0.987 total time=   2.0s\n",
      "[CV 5/10] END ...........C=10, solver=newton-cg;, score=0.987 total time=   1.8s\n",
      "[CV 2/10] END ...............C=20, solver=lbfgs;, score=0.986 total time=   0.3s\n",
      "[CV 5/10] END ...............C=20, solver=lbfgs;, score=0.987 total time=   0.3s\n",
      "[CV 9/10] END ...............C=20, solver=lbfgs;, score=0.986 total time=   0.4s\n",
      "[CV 5/10] END ...........C=20, solver=liblinear;, score=0.987 total time=   1.5s\n",
      "[CV 6/10] END .................C=20, solver=sag;, score=0.987 total time=   1.8s\n",
      "[CV 8/10] END ...........C=30, solver=liblinear;, score=0.987 total time=   1.5s\n",
      "[CV 2/10] END ................C=30, solver=saga;, score=0.986 total time=   2.8s\n",
      "[CV 2/10] END .alpha=0.1, class_weight=balanced;, score=0.951 total time=   0.2s\n",
      "[CV 3/10] END alpha=1e-11, class_weight=balanced;, score=0.950 total time=   0.1s\n",
      "[CV 1/10] END .........C=0.01, solver=liblinear;, score=0.984 total time=   1.2s\n",
      "[CV 7/10] END ..............C=0.01, solver=saga;, score=0.987 total time=   1.5s\n",
      "[CV 7/10] END ....C=0.1, solver=newton-cholesky;, score=0.987 total time=   0.4s\n",
      "[CV 10/10] END ..............C=0.1, solver=saga;, score=0.986 total time=   2.8s\n",
      "[CV 4/10] END ................C=5, solver=lbfgs;, score=0.985 total time=   0.4s\n",
      "[CV 5/10] END ............C=5, solver=liblinear;, score=0.987 total time=   1.3s\n",
      "[CV 10/10] END ...........C=5, solver=newton-cg;, score=0.986 total time=   1.4s\n",
      "[CV 2/10] END ...............C=10, solver=lbfgs;, score=0.986 total time=   0.3s\n",
      "[CV 5/10] END ...............C=10, solver=lbfgs;, score=0.987 total time=   0.3s\n",
      "[CV 9/10] END ...............C=10, solver=lbfgs;, score=0.986 total time=   0.4s\n",
      "[CV 4/10] END ...........C=10, solver=newton-cg;, score=0.985 total time=   1.7s\n",
      "[CV 1/10] END ...............C=20, solver=lbfgs;, score=0.985 total time=   0.4s\n",
      "[CV 4/10] END ...............C=20, solver=lbfgs;, score=0.985 total time=   0.3s\n",
      "[CV 7/10] END ...............C=20, solver=lbfgs;, score=0.987 total time=   0.4s\n",
      "[CV 3/10] END ...........C=20, solver=liblinear;, score=0.986 total time=   1.4s\n",
      "[CV 3/10] END .................C=20, solver=sag;, score=0.986 total time=   2.3s\n",
      "[CV 8/10] END ...........C=30, solver=newton-cg;, score=0.987 total time=   1.3s\n",
      "[CV 6/10] END ................C=30, solver=saga;, score=0.987 total time=   2.7s\n"
     ]
    }
   ],
   "source": [
    "#model5\n",
    "best_LogR = LogisticRegression( penalty='l2', solver= 'lbfgs', C=1)\n",
    "X_proc = preprocessor.fit_transform(df_train[[\"age\",\"total_pages_visited\",\"country\",\"new_user\",\"source\"]])\n",
    "best_LogR.fit(X_proc,Y)\n",
    "X_test_comp = preprocessor.transform(df_test)\n",
    "Y_test_comp =best_LogR.predict(X_test_comp)\n",
    "df_test_pred = pd.DataFrame(data=Y_test_comp, columns=['converted'])\n",
    "df_test_pred.to_csv('conversion_data_test_predictions_REDA-model5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c886fa-601b-4881-a0b9-16eabe3f16c0",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7266b0a-28d8-49c5-bfdb-95ec34036643",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "Best hyperparameters :  {'alpha': 0.01, 'class_weight': None}\n",
      "Best validation accuracy :  0.9695691913782332\n"
     ]
    }
   ],
   "source": [
    "model = RidgeClassifier()\n",
    "params = {\n",
    "    'alpha': [1e-2, 1e-1, 1e-3,1e-4,1e-10,1e-11],\n",
    "    'class_weight':[None, 'balanced']\n",
    "}\n",
    "gridsearch = GridSearchCV(model, param_grid = params, cv = 10, n_jobs=-1, verbose=3) # cv : the number of folds to be used for CV\n",
    "gridsearch.fit(X_train, Y_train)\n",
    "print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
    "print(\"Best validation accuracy : \", gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd36d210-014e-4ff2-9518-33ab6f829ada",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9694989106753813\n",
      "[[-0.02202347  0.18138024  0.08250978  0.07193744  0.05161908 -0.08126819\n",
      "  -0.00789379 -0.00226407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     82620\n",
      "           1       1.00      0.05      0.10      2754\n",
      "\n",
      "    accuracy                           0.97     85374\n",
      "   macro avg       0.98      0.53      0.54     85374\n",
      "weighted avg       0.97      0.97      0.96     85374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_ridge= RidgeClassifier(0.01)\n",
    "best_ridge.fit(X_train,Y_train)\n",
    "Y_test_pred = best_ridge.predict(X_test)\n",
    "print(best_ridge.score(X_test, Y_test))\n",
    "print(best_ridge.coef_)\n",
    "print(classification_report(y_true = Y_test, y_pred=best_ridge.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89ff3d64-daf7-403c-a6c6-1363e987fa4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [7],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [9],\n",
       "       [8]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sel.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ad327-67fc-4ff4-b204-6b3ddcf56c23",
   "metadata": {},
   "source": [
    "### FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6efcd792-739d-4bd6-8a6d-84c5d12b72db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9823014032375196\n",
      "0.9832384566729918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     82620\n",
      "           1       0.81      0.59      0.68      2754\n",
      "\n",
      "    accuracy                           0.98     85374\n",
      "   macro avg       0.90      0.79      0.84     85374\n",
      "weighted avg       0.98      0.98      0.98     85374\n",
      "\n",
      "0.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_sel = df_train[[\"total_pages_visited\"]]\n",
    "Y_sel = df_train[\"converted\"]\n",
    "X_train_sel, X_test_sel, Y_train_sel, Y_test_sel = train_test_split(X_sel, Y_sel, test_size = 0.3, random_state = 0, stratify=Y)\n",
    "scaler = StandardScaler()\n",
    "X_train_sel = scaler.fit_transform(X_train_sel)\n",
    "X_test_sel = scaler.transform(X_test_sel)\n",
    "best_LogR = LogisticRegression( penalty='l2', solver= 'lbfgs', C=1)\n",
    "best_LogR.fit(X_train_sel, Y_train_sel)\n",
    "print(best_LogR.score(X_test_sel,Y_test_sel))\n",
    "print(best_LogR.score(X_train_sel,Y_train_sel))\n",
    "print(classification_report(y_true = Y_test, y_pred=best_LogR.predict(X_test_sel)))\n",
    "print(recall_score(y_true = Y_test, y_pred=best_LogR.predict(X_test_sel)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78e32861-fd73-4bb7-a2a8-46c896184263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model5-1feature\n",
    "best_LogR = LogisticRegression( penalty='l2', solver= 'lbfgs', C=1)\n",
    "scaler = StandardScaler()\n",
    "X_proc = scaler.fit_transform(df_train[[\"total_pages_visited\"]])\n",
    "best_LogR.fit(X_proc,Y)\n",
    "X_test_comp = scaler.transform(df_test[[\"total_pages_visited\"]])\n",
    "Y_test_comp =best_LogR.predict(X_test_comp)\n",
    "df_test_pred = pd.DataFrame(data=Y_test_comp, columns=['converted'])\n",
    "df_test_pred.to_csv('conversion_data_test_predictions_REDA-model5-1feature.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c9c66-149c-4740-ae74-767a4072894a",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b0b288be-6bb3-4e81-bcb7-501851fe6899",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "...Done.\n",
      "Best hyperparameters :  {'C': 7, 'class_weight': {0: 1, 1: 2}, 'gamma': 1e-05, 'kernel': 'linear'}\n",
      "Best validation accuracy :  0.8810834478102058\n"
     ]
    }
   ],
   "source": [
    "classifier = SVC(gamma= 1e-5,)\n",
    "\n",
    "params = {\n",
    "    'kernel':['linear', 'poly', 'rbf'],\n",
    "    'C' :[10,7],\n",
    "    'class_weight':[{0:1,1:2},{0:1,1:3}]\n",
    "}\n",
    "gridsearch = GridSearchCV(classifier, param_grid = params, cv = 3, n_jobs=-1, verbose=1,scoring='f1_macro') # cv : the number of folds to be used for CV\n",
    "gridsearch.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
    "print(\"Best validation accuracy : \", gridsearch.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de2e0a60-3e52-4f92-a094-3963bce8df30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     82620\n",
      "           1       0.77      0.76      0.77      2754\n",
      "\n",
      "    accuracy                           0.98     85374\n",
      "   macro avg       0.88      0.88      0.88     85374\n",
      "weighted avg       0.98      0.98      0.98     85374\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f9c3ec2b310>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAGwCAYAAAAqpFaiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRG0lEQVR4nO3de1yUdfr/8dfIYTgoE4iAU6hYRBpWhi2ilbYe0ERr+37XipZ0M7QoWTbJtuxgBzEzDxWbmbXqmv2ob65tbcViu2XreqaoPKSWpJggliMoIsf79wd514jVjAOizvu5j/vxiPu+7vv+zMgy11yfw20xDMNARERE5Be0a+sGiIiIyJlBSYOIiIi4REmDiIiIuERJg4iIiLhESYOIiIi4REmDiIiIuERJg4iIiLjEt60b4InGxkb27t1Lhw4dsFgsbd0cERFxk2EYHDp0CLvdTrt2rfc99ujRo9TW1np8HX9/fwICAlqgRWemMzpp2Lt3L9HR0W3dDBER8VBJSQnnnXdeq1z76NGjxHRtT1l5g8fXioqKori42GsThzM6aejQoQMAuz7uRkh79bTI2ek3F/Zq6yaItJp66ljFu+bf89ZQW1tLWXkDuwq7EdLh5D8rKg810jXha2pra5U0nImOdUmEtG/n0S+CyOnM1+LX1k0QaT3fP8jgVHQxt+9goX2Hk79PI+oGP6OTBhEREVc1GI00ePC0pQajseUac4ZS0iAiIl6hEYNGTj5r8OTcs4Vq+iIiIuISJQ0iIuIVGlvgf+6or6/nwQcfJCYmhsDAQLp3785jjz1GY+MP1zEMg6lTp2K32wkMDGTgwIFs3rzZ6To1NTVMnDiR8PBwgoODGTVqFHv27HGKcTgcpKWlYbPZsNlspKWlcfDgQaeY3bt3M3LkSIKDgwkPDyczM9PtaahKGkRExCs0GIbHmztmzJjBCy+8QG5uLlu3buWpp55i5syZPPfcc2bMU089xezZs8nNzWXDhg1ERUUxZMgQDh06ZMZkZWWxfPly8vLyWLVqFYcPHyYlJYWGhh+mkKamplJUVER+fj75+fkUFRWRlpb2w2tvaGDEiBFUVVWxatUq8vLyWLZsGZMmTXLrNVkMw8134TRSWVmJzWbDsb27Zk/IWSvZfllbN0Gk1dQbdXzI36moqCAkJKRV7nHss6Lki3M9nnIZfdE3lJSUOLXVarVitVqbxaekpBAZGcnLL79s7vuf//kfgoKCWLJkCYZhYLfbycrK4r777gOaqgqRkZHMmDGDCRMmUFFRQadOnViyZAk33ngj8MMaRe+++y7Jycls3bqVnj17snbtWhITEwFYu3YtSUlJfPHFF8TFxfHee++RkpJCSUkJdrsdgLy8PMaOHUt5ebnL770+aUVExCscGwjpyQYQHR1tdgPYbDamT59+wvtdeeWV/Otf/2L79u0AfPrpp6xatYprr70WgOLiYsrKyhg6dKh5jtVqZcCAAaxevRqAwsJC6urqnGLsdjvx8fFmzJo1a7DZbGbCANC3b19sNptTTHx8vJkwACQnJ1NTU0NhYaHL76FmT4iIiFdoxKChBWZPnKjScCL33XcfFRUVXHTRRfj4+NDQ0MC0adO4+eabASgrKwMgMjLS6bzIyEh27dplxvj7+xMaGtos5tj5ZWVlRERENLt/RESEU8zx9wkNDcXf39+McYWSBhERETeEhIS4VM5/7bXXeOWVV3j11Ve5+OKLKSoqIisrC7vdzpgxY8y44xe2MgzjFxe7Oj7mRPEnE/NL1D0hIiJeoaW6J1x177338qc//YmbbrqJXr16kZaWxh//+EezOyMqKgqg2Tf98vJysyoQFRVFbW0tDofjZ2P27dvX7P779+93ijn+Pg6Hg7q6umYViJ+jpEFERLzCqZ49ceTIkWZP7vTx8TGnXMbExBAVFcWKFSvM47W1taxcuZJ+/foBkJCQgJ+fn1NMaWkpmzZtMmOSkpKoqKhg/fr1Zsy6deuoqKhwitm0aROlpaVmTEFBAVarlYSEBJdfk7onREREWsHIkSOZNm0aXbp04eKLL+aTTz5h9uzZ3HbbbUBTd0FWVhY5OTnExsYSGxtLTk4OQUFBpKamAmCz2Rg3bhyTJk2iY8eOhIWFkZ2dTa9evRg8eDAAPXr0YNiwYaSnpzN//nwAxo8fT0pKCnFxcQAMHTqUnj17kpaWxsyZMzlw4ADZ2dmkp6e7NWtFSYOIiHiFxu83T853x3PPPcdDDz1ERkYG5eXl2O12JkyYwMMPP2zGTJ48merqajIyMnA4HCQmJlJQUOD01M85c+bg6+vL6NGjqa6uZtCgQSxatAgfHx8zZunSpWRmZpqzLEaNGkVubq553MfHh3feeYeMjAz69+9PYGAgqampPP300269Jq3TIHKa0zoNcjY7les0bN4aQQcPPisOHWrk4h7lrdrW050qDSIi4hUaDDx8ymXLteVMpa/nIiIi4hJVGkRExCuc6jENZyMlDSIi4hUasdCA6wsZneh8b6fuCREREXGJKg0iIuIVGo2mzZPzvZ2SBhER8QoNHnZPeHLu2ULdEyIiIuISVRpERMQrqNLgOSUNIiLiFRoNC42GB7MnPDj3bKHuCREREXGJKg0iIuIV1D3hOSUNIiLiFRpoR4MHBfaGFmzLmUpJg4iIeAXDwzENhsY0aEyDiIiIuEaVBhER8Qoa0+A5JQ0iIuIVGox2NBgejGnQMtLqnhARERHXqNIgIiJeoRELjR58V25EpQYlDSIi4hU0psFz6p4QERERl6jSICIiXsHzgZDqnlDSICIiXqFpTIMHD6xS94S6J0RERMQ1qjSIiIhXaPTw2ROaPaGkQUREvITGNHhOSYOIiHiFRtppnQYPaUyDiIiIuESVBhER8QoNhoUGDx5v7cm5ZwslDSIi4hUaPBwI2aDuCXVPiIiIiGtUaRAREa/QaLSj0YPZE42aPaGkQUREvIO6Jzyn7gkRERFxiZIGERHxCo38MIPiZLZGN+/XrVs3LBZLs+2uu+4CwDAMpk6dit1uJzAwkIEDB7J582ana9TU1DBx4kTCw8MJDg5m1KhR7NmzxynG4XCQlpaGzWbDZrORlpbGwYMHnWJ2797NyJEjCQ4OJjw8nMzMTGpra918RUoaRETESxxb3MmTzR0bNmygtLTU3FasWAHAb3/7WwCeeuopZs+eTW5uLhs2bCAqKoohQ4Zw6NAh8xpZWVksX76cvLw8Vq1axeHDh0lJSaGhocGMSU1NpaioiPz8fPLz8ykqKiItLc083tDQwIgRI6iqqmLVqlXk5eWxbNkyJk2a5PZ7aDGMM3dkR2VlJTabDcf27oR0UP4jZ6dk+2Vt3QSRVlNv1PEhf6eiooKQkJBWucexz4p5H19BYPuTH8pXfbieOy/fcNJtzcrK4h//+Ac7duwAwG63k5WVxX333Qc0VRUiIyOZMWMGEyZMoKKigk6dOrFkyRJuvPFGAPbu3Ut0dDTvvvsuycnJbN26lZ49e7J27VoSExMBWLt2LUlJSXzxxRfExcXx3nvvkZKSQklJCXa7HYC8vDzGjh1LeXm5W69Fn7QiIuIVjj17wpMNmpKQH281NTW/eO/a2lpeeeUVbrvtNiwWC8XFxZSVlTF06FAzxmq1MmDAAFavXg1AYWEhdXV1TjF2u534+HgzZs2aNdhsNjNhAOjbty82m80pJj4+3kwYAJKTk6mpqaGwsNCt91BJg4iIeIVGLB5vANHR0eb4AZvNxvTp03/x3m+++SYHDx5k7NixAJSVlQEQGRnpFBcZGWkeKysrw9/fn9DQ0J+NiYiIaHa/iIgIp5jj7xMaGoq/v78Z4ypNuRQREa/g+VMum84tKSlxKulbrdZfPPfll19m+PDhTt/2ASwW56WpDcNotu94x8ecKP5kYlyhSoOIiIgbQkJCnLZfShp27drF+++/z+23327ui4qKAmj2Tb+8vNysCkRFRVFbW4vD4fjZmH379jW75/79+51ijr+Pw+Ggrq6uWQXilyhpEBERr3BscSdPtpOxcOFCIiIiGDFihLkvJiaGqKgoc0YFNI17WLlyJf369QMgISEBPz8/p5jS0lI2bdpkxiQlJVFRUcH69evNmHXr1lFRUeEUs2nTJkpLS82YgoICrFYrCQkJbr0WdU+IiIhXaDQsNHrwpMqTObexsZGFCxcyZswYfH1/+Mi1WCxkZWWRk5NDbGwssbGx5OTkEBQURGpqKgA2m41x48YxadIkOnbsSFhYGNnZ2fTq1YvBgwcD0KNHD4YNG0Z6ejrz588HYPz48aSkpBAXFwfA0KFD6dmzJ2lpacycOZMDBw6QnZ1Nenq627NAlDSIiIi0kvfff5/du3dz2223NTs2efJkqqurycjIwOFwkJiYSEFBAR06dDBj5syZg6+vL6NHj6a6uppBgwaxaNEifHx8zJilS5eSmZlpzrIYNWoUubm55nEfHx/eeecdMjIy6N+/P4GBgaSmpvL000+7/Xq0ToPIaU7rNMjZ7FSu0/DkhgEEeLBOw9HD9fzpipWt2tbTnSoNIiLiFTx/yqW+nOodEBEREZeo0iAiIl6hAQsNnPxASE/OPVsoaRAREa+g7gnP6R0QERERl6jSICIiXqEBz7oYGn455KynpEFERLyCuic8p6RBRES8Qks9sMqb6R0QERERl6jSICIiXsHAQqMHYxoMTblU0iAiIt5B3ROe0zsgIiIiLlGlQUREvEJbPBr7bKOkQUREvEID7WjwoMDuyblnC70DIiIi4hJVGkRExCuoe8JzShpERMQrNNKORg8K7J6ce7bQOyAiIiIuUaVBRES8QoNhocGDLgZPzj1bKGkQERGvoDENnlPSICIiXsHw8CmXhlaE1JgGERERcY0qDSIi4hUasNDgwUOnPDn3bKGkQUREvEKj4dm4hEajBRtzhlL3hIiIiLhElYazWEM9LJkVxb//Fopjvx9hEXUMGX2A1Kx9tGsH9XWwaEZnNvw7hNJd/gSHNNL7qkOMe2AvHaPqzevU1lhY8JidD98Mpeaohd5XHubu6XvoZK8zYw4d9GHeQ+eypsAGQNLQCjKe+Ib2toZm7ao84MOdQ+L4ttSfZVs/P2GMSEvqGFXHuCl7ueKaQ/gHNvLNTiuz74nmy8+DAOg//CDXpn1H7CXV2MIauHPIhezcHNjsOj0Sqhh7XxkXXX6E+jr4anMgD/6uO7VH9f3rTNDo4UBIT849WyhpOIu99udI3vlrONnP7KZr3FF2fBrIrD92ITikgd/c/i011e348vMgUrP20b1nNYcrfHjhkXN5ZGx3cvO3m9d54ZFzWbcihPvnfU1IaAMvPmbn4Vu7k/vPbfj4NMU8eVdXvi31Y9rSrwB4ZnI0T03swmN/LW7WrtmTuhDT4yjflvqfkvdBvFt7Wz2z/76Dz1a358Hfdefgt7507lZDVaWPGRMQ1MiWDcH85x/n8Men95zwOj0Sqpi2dCd5uRE8/+C51NVZ6N6zGqPxVL0S8VQjFho9GJfgyblnizZPGp5//nlmzpxJaWkpF198MXPnzuWqq65q62adFbYWBpGUXEHi4EoAoqJr+eDNQ+z4tOnbVXBII0++9pXTORlP7CHz2jjK9/gRcV4dVZXt+Of/C+PeZ3dz+dWHAbjvuV38rs/FfPKfDvQZeIjdO6xs/CCEZ/6xnYsuPwJA1swSskZeSMmXVqIvqDGv//bijlRV+nDLH8vY8O+QU/E2iJcbfVc53+71Z9Yfu5j79u1xTlj/tSwMgMjzan/yOhOm7uXNl8N5PTfS3Le32NrCrRU5vbVpreW1114jKyuLKVOm8Mknn3DVVVcxfPhwdu/e3ZbNOmvEX1FF0aoO7Pmq6Q/bV5sD2Lw+mCt+XfmT51RV+mCxGAR/32Ww47Mg6uvakTDgkBnTMaqerhcdZcuGYAC2bgwmOKTBTBgAeiQcITikgS0bg819u7ZbeXVOFPc+swuLqnxyivQdWsn2TwOZMv9rXvtsM38u2Mbw1O/cuoatYx09Eo5w8Dtf5ry1g7xPNzNz2Zdc/KvDrdRqaQ3HVoT0ZPN2bfqne/bs2YwbN47bb7+dHj16MHfuXKKjo5k3b15bNuusMfrucgZe7+D2qy/i2i6XctfQOH6Tvp9rfnPwhPG1Ry38JcfONb9xENyhqeZ6oNwXP/9GOpzjPO4gNLwOx/6mQtWB/b6cE17X7Hrn/CimtsbC9Ixu3P7QXiLOax4r0lo6d6kl5dbv2Fts5YHUGN75azh3Pv4Ng//3gOvX6NpUgUi7Zx/vLe3IlFti+PLzQJ58bSf2mJpfOFtOF8fGNHiyebs2656ora2lsLCQP/3pT077hw4dyurVq094Tk1NDTU1P/wftLLyp78xC6z8+zn8a1kof/rzLrrGHeWrzYG88Mi5dIysY8hoh1NsfR3k3NkNoxHunn7iPt0fMwwLP+7eO1H+bRgWc//C6Z3pcsFRBv2P4wSRIq3H0g52fBbIwic7A/DVpiC6xh1lxK3f8f4bYS5do933nxXvvtKRgtfCzOtcduVhkm86wMLpnVul7SKnmzZLGr799lsaGhqIjIx02h8ZGUlZWdkJz5k+fTqPPvroqWjeWWHB43ZuvLucgdcfBCCmx1HK9/iT91ykU9JQXwfTJnSjrMSfp17/0qwyAIRF1FNX245DB32cqg0Hv/OlZ5+qpphO9Ti+9Wt2/4rvfDmnU9MsjKJVHfj6iwCGR5/TdPD7+c6/jY/n5sx93Hrvif/NRTx1oNyXXdsDnPaV7LBy5bUHXb7Gd/ua/lQ2u86XViLO/elxEHJ6acTDZ09oIGTbr9NgsTj/IxiG0WzfMffffz8VFRXmVlJSciqaeMaqOdoOSzvn1Uja+RgYP9p1LGH4ptjKk699SUiYczdE7CVH8PVr5OOPOpj7vtvny64vAuh5RVPS0KNPFVWVPnzxSZAZ88XHQVRV+piJxUMvFTPv/W3MW9G0ZT3d9G83a/kORv3+2xZ93SI/tmVDMNHnO3chnNu9hvJvXJ+9s6/En29LfTnv/KPNr7NHs4DOFMb3sydOdjOUNLRdpSE8PBwfH59mVYXy8vJm1YdjrFYrVqtGK7uq75BK8p6NJOLcuqbuiU2B/G1+BENvahoE1lAPj6c39c0+9tedNDZYOFDe9CvR4ZwG/PwNgkMaSb75AC8+aicktJ4O5zSw4HE73S46Su+rmgZHdomtoc81lcy9N5o/zGhKBp6ZHE3i4Apz5oS9m/O3sYoDvua5WqdBWtPfXuzEnLd2cNPEfXz09jnE9T7Ctb87wNx7zzNjOpxTT6dz6+gY2TTeJvr75MBR7otjvx9g4Y15EaRll7FzSyA7Nwcy+LcHiD6/hifSXevikLanp1x6rs0qDf7+/iQkJLBixQqn/StWrKBfv35t1KqzS8YTe7hyRAW5959H+oCLWPCYnWvTvmXM5KZEbX+pP2sLbHxb6k/GkIu4+bJ4c/vxrIc7pn5Dv2EVTLujG/dcF4s1oJFHF+8012gAuC93FzEXVfPAzefzwM3nE9OjmsnPaRaMtL3tnwbx2LgYBl5/kPn/3kZq1j5eeNjOB8tDzZi+QyuZt2I7T7zStK7IAy/sZt6K7Yy49YdZFstf6kRebgR3PLqXee9vp/dVh7n/5u6U7tIXGflp33zzDb/73e/o2LEjQUFBXHbZZRQWFprHDcNg6tSp2O12AgMDGThwIJs3b3a6Rk1NDRMnTiQ8PJzg4GBGjRrFnj3OY88cDgdpaWnYbDZsNhtpaWkcPHjQKWb37t2MHDmS4OBgwsPDyczMpLbWve41i2EYbbaa9muvvUZaWhovvPACSUlJvPjiiyxYsIDNmzfTtWvXXzy/srISm82GY3t3Qjq0eU+LSKtItl/W1k0QaTX1Rh0f8ncqKioICWmdtVuOfVb8ZsXv8Qs++e6kuqpalg9Z6HJbHQ4HvXv35pprruHOO+8kIiKCr776im7dunH++ecDMGPGDKZNm8aiRYu48MILeeKJJ/joo4/Ytm0bHTo0dQvfeeedvP322yxatIiOHTsyadIkDhw4QGFhIT7ff3sbPnw4e/bs4cUXXwRg/PjxdOvWjbfffhuAhoYGLrvsMjp16sSsWbP47rvvGDNmDDfccAPPPfecy+9Bmy7udOONN/Ldd9/x2GOPUVpaSnx8PO+++65LCYOIiIg7TnX3xIwZM4iOjmbhwoXmvm7dupn/bRgGc+fOZcqUKdxwww0ALF68mMjISF599VUmTJhARUUFL7/8MkuWLGHw4MEAvPLKK0RHR/P++++TnJzM1q1byc/PZ+3atSQmJgKwYMECkpKS2LZtG3FxcRQUFLBlyxZKSkqw2+0AzJo1i7FjxzJt2jSXE7Y2/3qekZHB119/TU1NDYWFhVx99dVt3SQREZGfVFlZ6bT9eCmAH3vrrbfo06cPv/3tb4mIiKB3794sWLDAPF5cXExZWRlDhw4191mtVgYMGGAuPVBYWEhdXZ1TjN1uJz4+3oxZs2YNNpvNTBgA+vbti81mc4qJj483EwaA5ORk87PXVW2eNIiIiJwKnsyc+PFzK6Kjo82xAzabjenTp5/wfjt37mTevHnExsbyz3/+kzvuuIPMzEz++te/ApgTAX5u6YGysjL8/f0JDQ392ZiIiIhm94+IiHCKOf4+oaGh+Pv7/+QyByfS5s+eEBERORVaqnuipKTEqZz/U7P6Ghsb6dOnDzk5OQD07t2bzZs3M2/ePG699VYzzp2lB34q5kTxJxPzS1RpEBERcUNISIjT9lNJQ+fOnenZs6fTvh49epjPV4qKigL42aUHoqKiqK2txeFw/GzMvn37mt1///79TjHH38fhcFBXV/eTyxyciJIGERHxCscqDZ5s7ujfvz/btm1z2rd9+3ZzsH9MTAxRUVFOSw/U1taycuVKc+mBhIQE/Pz8nGJKS0vZtGmTGZOUlERFRQXr1683Y9atW0dFRYVTzKZNmygtLTVjCgoKsFqtJCQkuPya1D0hIiJe4VTPnvjjH/9Iv379yMnJYfTo0axfv54XX3zRnBZpsVjIysoiJyeH2NhYYmNjycnJISgoiNTUVABsNhvjxo1j0qRJdOzYkbCwMLKzs+nVq5c5m6JHjx4MGzaM9PR05s+fDzRNuUxJSSEuLg5oeq5Tz549SUtLY+bMmRw4cIDs7GzS09PdmuqqpEFERKQVXHHFFSxfvpz777+fxx57jJiYGObOncstt9xixkyePJnq6moyMjJwOBwkJiZSUFBgrtEAMGfOHHx9fRk9ejTV1dUMGjSIRYsWmWs0ACxdupTMzExzlsWoUaPIzc01j/v4+PDOO++QkZFB//79CQwMJDU1laefftqt19Smizt5Sos7iTfQ4k5yNjuVizsNeXeCx4s7rbh2fqu29XSnSoOIiHgFA8+eVHnGfsNuQUoaRETEK+iBVZ5TTV9ERERcokqDiIh4BVUaPKekQUREvIKSBs+pe0JERERcokqDiIh4BVUaPKekQUREvIJhWDA8+OD35NyzhbonRERExCWqNIiIiFdoxOLR4k6enHu2UNIgIiJeQWMaPKfuCREREXGJKg0iIuIVNBDSc0oaRETEK6h7wnNKGkRExCuo0uA5jWkQERERl6jSICIiXsHwsHtClQYlDSIi4iUMwDA8O9/bqXtCREREXKJKg4iIeIVGLFi0IqRHlDSIiIhX0OwJz6l7QkRERFyiSoOIiHiFRsOCRYs7eURJg4iIeAXD8HD2hKZPqHtCREREXKNKg4iIeAUNhPSckgYREfEKSho8p6RBRES8ggZCek5jGkRERMQlqjSIiIhX0OwJzylpEBERr9CUNHgypqEFG3OGUveEiIiIuESVBhER8QqaPeE5JQ0iIuIVjO83T873duqeEBEREZcoaRAREa9wrHvCk80dU6dOxWKxOG1RUVE/ao/B1KlTsdvtBAYGMnDgQDZv3ux0jZqaGiZOnEh4eDjBwcGMGjWKPXv2OMU4HA7S0tKw2WzYbDbS0tI4ePCgU8zu3bsZOXIkwcHBhIeHk5mZSW1trXtvIEoaRETEWxgtsLnp4osvprS01Nw+//xz89hTTz3F7Nmzyc3NZcOGDURFRTFkyBAOHTpkxmRlZbF8+XLy8vJYtWoVhw8fJiUlhYaGBjMmNTWVoqIi8vPzyc/Pp6ioiLS0NPN4Q0MDI0aMoKqqilWrVpGXl8eyZcuYNGmS269HYxpERMQ7eDgQku/PraysdNpttVqxWq0nPMXX19epumBeyjCYO3cuU6ZM4YYbbgBg8eLFREZG8uqrrzJhwgQqKip4+eWXWbJkCYMHDwbglVdeITo6mvfff5/k5GS2bt1Kfn4+a9euJTExEYAFCxaQlJTEtm3biIuLo6CggC1btlBSUoLdbgdg1qxZjB07lmnTphESEuLyW6BKg4iIiBuio6PNrgCbzcb06dN/MnbHjh3Y7XZiYmK46aab2LlzJwDFxcWUlZUxdOhQM9ZqtTJgwABWr14NQGFhIXV1dU4xdrud+Ph4M2bNmjXYbDYzYQDo27cvNpvNKSY+Pt5MGACSk5OpqamhsLDQrdeuSoOIiHiFlloRsqSkxOnb+U9VGRITE/nrX//KhRdeyL59+3jiiSfo168fmzdvpqysDIDIyEincyIjI9m1axcAZWVl+Pv7Exoa2izm2PllZWVEREQ0u3dERIRTzPH3CQ0Nxd/f34xxlZIGERHxCi21TkNISIhLJf3hw4eb/92rVy+SkpI4//zzWbx4MX379gXAYnFuj2EYzfY1b4dzzIniTybGFeqeEBEROQWCg4Pp1asXO3bsMMc5HP9Nv7y83KwKREVFUVtbi8Ph+NmYffv2NbvX/v37nWKOv4/D4aCurq5ZBeKXKGkQERHvYFg83zxQU1PD1q1b6dy5MzExMURFRbFixQrzeG1tLStXrqRfv34AJCQk4Ofn5xRTWlrKpk2bzJikpCQqKipYv369GbNu3ToqKiqcYjZt2kRpaakZU1BQgNVqJSEhwa3XoO4JERHxCqf6KZfZ2dmMHDmSLl26UF5ezhNPPEFlZSVjxozBYrGQlZVFTk4OsbGxxMbGkpOTQ1BQEKmpqQDYbDbGjRvHpEmT6NixI2FhYWRnZ9OrVy9zNkWPHj0YNmwY6enpzJ8/H4Dx48eTkpJCXFwcAEOHDqVnz56kpaUxc+ZMDhw4QHZ2Nunp6W7NnAAlDSIiIq1iz5493HzzzXz77bd06tSJvn37snbtWrp27QrA5MmTqa6uJiMjA4fDQWJiIgUFBXTo0MG8xpw5c/D19WX06NFUV1czaNAgFi1ahI+PjxmzdOlSMjMzzVkWo0aNIjc31zzu4+PDO++8Q0ZGBv379ycwMJDU1FSefvppt1+TxTDO3Id9VlZWYrPZcGzvTkgH9bTI2SnZfllbN0Gk1dQbdXzI36moqHD7W6+rjn1WdF3wEO2CAk76Oo1HjrIr/fFWbevpTpUGERHxCnrKpedcShqeffZZly+YmZl50o0RERGR05dLScOcOXNcupjFYlHSICIip68ztkP+9OBS0lBcXNza7RAREWlV6p7w3EmPHqytrWXbtm3U19e3ZHtERERaRxs85fJs43bScOTIEcaNG0dQUBAXX3wxu3fvBprGMjz55JMt3kARERE5PbidNNx///18+umnfPjhhwQE/DB1ZfDgwbz22mst2jgREZGWY2mBzbu5PeXyzTff5LXXXqNv375OD7ro2bMnX331VYs2TkREpMV42sWg7gn3Kw379+8/4WM4q6qq3H5aloiIiJw53E4arrjiCt555x3z52OJwoIFC0hKSmq5lomIiLQkDYT0mNvdE9OnT2fYsGFs2bKF+vp6nnnmGTZv3syaNWtYuXJla7RRRETEc54+qVJTLt2vNPTr14///ve/HDlyhPPPP5+CggIiIyNZs2aN24/YFBERkTPHST17olevXixevLil2yIiItJqTvWjsc9GJ5U0NDQ0sHz5crZu3YrFYqFHjx5cd911+Prq+VciInKa0uwJj7n9Kb9p0yauu+46ysrKiIuLA2D79u106tSJt956i169erV4I0VERKTtuT2m4fbbb+fiiy9mz549fPzxx3z88ceUlJRwySWXMH78+NZoo4iIiOeODYT0ZPNyblcaPv30UzZu3EhoaKi5LzQ0lGnTpnHFFVe0aONERERaisVo2jw539u5XWmIi4tj3759zfaXl5dzwQUXtEijREREWpzWafCYS0lDZWWlueXk5JCZmckbb7zBnj172LNnD2+88QZZWVnMmDGjtdsrIiIibcSl7olzzjnHaYlowzAYPXq0uc/4fh7KyJEjaWhoaIVmioiIeEiLO3nMpaThgw8+aO12iIiItC5NufSYS0nDgAEDWrsdIiIicpo76dWYjhw5wu7du6mtrXXaf8kll3jcKBERkRanSoPH3E4a9u/fz+9//3vee++9Ex7XmAYRETktKWnwmNtTLrOysnA4HKxdu5bAwEDy8/NZvHgxsbGxvPXWW63RRhERETkNuF1p+Pe//83f//53rrjiCtq1a0fXrl0ZMmQIISEhTJ8+nREjRrRGO0VERDyj2RMec7vSUFVVRUREBABhYWHs378faHry5ccff9yyrRMREWkhx1aE9GTzdie1IuS2bdsAuOyyy5g/fz7ffPMNL7zwAp07d27xBoqIiMjpwe3uiaysLEpLSwF45JFHSE5OZunSpfj7+7No0aKWbp+IiEjL0EBIj7mdNNxyyy3mf/fu3Zuvv/6aL774gi5duhAeHt6ijRMREZHTx0mv03BMUFAQl19+eUu0RUREpNVY8PAply3WkjOXS0nDPffc4/IFZ8+efdKNERERkdOXS0nDJ5984tLFfvxQq1PpNxf2wtfi1yb3FmltFj//tm6CSKuxGBaoO0U305RLj+mBVSIi4h00ENJjbk+5FBEREfdMnz4di8VCVlaWuc8wDKZOnYrdbicwMJCBAweyefNmp/NqamqYOHEi4eHhBAcHM2rUKPbs2eMU43A4SEtLw2azYbPZSEtL4+DBg04xu3fvZuTIkQQHBxMeHk5mZmazZ0e5QkmDiIh4B6MFtpOwYcMGXnzxxWYPdHzqqaeYPXs2ubm5bNiwgaioKIYMGcKhQ4fMmKysLJYvX05eXh6rVq3i8OHDpKSkOD3nKTU1laKiIvLz88nPz6eoqIi0tDTzeENDAyNGjKCqqopVq1aRl5fHsmXLmDRpktuvRUmDiIh4hbZYEfLw4cPccsstLFiwgNDQUHO/YRjMnTuXKVOmcMMNNxAfH8/ixYs5cuQIr776KgAVFRW8/PLLzJo1i8GDB9O7d29eeeUVPv/8c95//30Atm7dSn5+Pi+99BJJSUkkJSWxYMEC/vGPf5gLMRYUFLBlyxZeeeUVevfuzeDBg5k1axYLFiygsrLSrdejpEFERMQNlZWVTltNTc1Pxt51112MGDGCwYMHO+0vLi6mrKyMoUOHmvusVisDBgxg9erVABQWFlJXV+cUY7fbiY+PN2PWrFmDzWYjMTHRjOnbty82m80pJj4+HrvdbsYkJydTU1NDYWGhW69dSYOIiHiHFuqeiI6ONscP2Gw2pk+ffsLb5eXl8fHHH5/weFlZGQCRkZFO+yMjI81jZWVl+Pv7O1UoThRz7HlQPxYREeEUc/x9QkND8ff3N2NcdVKLOy1ZsoQXXniB4uJi1qxZQ9euXZk7dy4xMTFcd911J3NJERGR1tVCsydKSkoICQkxd1ut1mahJSUl/OEPf6CgoICAgICfvOTxSxUYhvGLyxccH3Oi+JOJcYXblYZ58+Zxzz33cO2113Lw4EFzMMY555zD3Llz3b2ciIjIGSUkJMRpO1HSUFhYSHl5OQkJCfj6+uLr68vKlSt59tln8fX1Nb/5H/9Nv7y83DwWFRVFbW0tDofjZ2P27dvX7P779+93ijn+Pg6Hg7q6umYViF/idtLw3HPPsWDBAqZMmYKPj4+5v0+fPnz++efuXk5EROSUOJUDIQcNGsTnn39OUVGRufXp04dbbrmFoqIiunfvTlRUFCtWrDDPqa2tZeXKlfTr1w+AhIQE/Pz8nGJKS0vZtGmTGZOUlERFRQXr1683Y9atW0dFRYVTzKZNm8yHTULT4Eir1UpCQoJb76Hb3RPFxcX07t272X6r1UpVVZW7lxMRETk1TuGKkB06dCA+Pt5pX3BwMB07djT3Z2VlkZOTQ2xsLLGxseTk5BAUFERqaioANpuNcePGMWnSJDp27EhYWBjZ2dn06tXLHFjZo0cPhg0bRnp6OvPnzwdg/PjxpKSkEBcXB8DQoUPp2bMnaWlpzJw5kwMHDpCdnU16erpTN4sr3E4aYmJiKCoqomvXrk7733vvPXr27Onu5URERE6N02xFyMmTJ1NdXU1GRgYOh4PExEQKCgro0KGDGTNnzhx8fX0ZPXo01dXVDBo0iEWLFjlV+pcuXUpmZqY5y2LUqFHk5uaax318fHjnnXfIyMigf//+BAYGkpqaytNPP+12my2GYbj1NixcuJCHHnqIWbNmMW7cOF566SW++uorpk+fzksvvcRNN93kdiNOVmVlJTabjYFcp2dPyFlLz56Qs1m9UccHdf9HRUWF2996XXXssyJmag7tfmZQ4i9pPHqU4qkPtGpbT3duVxp+//vfU19fz+TJkzly5Aipqamce+65PPPMM6c0YRAREXHHyS7Q9OPzvd1JTblMT08nPT2db7/9lsbGxhPOERURETmtnGbdE2eik0oajgkPD2+pdoiIiMhp7qQGQv7cYhA7d+70qEEiIiKtwsPuCVUaTiJp+PFjPQHq6ur45JNPyM/P5957722pdomIiLQsdU94zO2k4Q9/+MMJ9//5z39m48aNHjdIRERETk8t9sCq4cOHs2zZspa6nIiISMtqoQdWeTOPBkL+2BtvvEFYWFhLXU5ERKRFacql59xOGnr37u00ENIwDMrKyti/fz/PP/98izZORERETh9uJw3XX3+908/t2rWjU6dODBw4kIsuuqil2iUiIiKnGbeShvr6erp160ZycjJRUVGt1SYREZGWp9kTHnNrIKSvry933nknNTU1rdUeERGRVnEqH419tnJ79kRiYiKffPJJa7RFRERETmNuj2nIyMhg0qRJ7Nmzh4SEBIKDg52OX3LJJS3WOBERkRalaoFHXE4abrvtNubOncuNN94IQGZmpnnMYrFgGAYWi4WGhoaWb6WIiIinNKbBYy4nDYsXL+bJJ5+kuLi4NdsjIiIipymXkwbDaEqxunbt2mqNERERaS1a3Mlzbo1p+LmnW4qIiJzW1D3hMbeShgsvvPAXE4cDBw541CARERE5PbmVNDz66KPYbLbWaouIiEirUfeE59xKGm666SYiIiJaqy0iIiKtR90THnN5cSeNZxAREfFubs+eEBEROSOp0uAxl5OGxsbG1myHiIhIq9KYBs+5vYy0iIjIGUmVBo+5/cAqERER8U6qNIiIiHdQpcFjShpERMQraEyD59Q9ISIiIi5RpUFERLyDuic8pqRBRES8gronPKfuCREREXGJKg0iIuId1D3hMSUNIiLiHZQ0eEzdEyIiIuISJQ0iIuIVLC2wuWPevHlccsklhISEEBISQlJSEu+995553DAMpk6dit1uJzAwkIEDB7J582ana9TU1DBx4kTCw8MJDg5m1KhR7NmzxynG4XCQlpaGzWbDZrORlpbGwYMHnWJ2797NyJEjCQ4OJjw8nMzMTGpra918RUoaRETEWxgtsLnhvPPO48knn2Tjxo1s3LiRX//611x33XVmYvDUU08xe/ZscnNz2bBhA1FRUQwZMoRDhw6Z18jKymL58uXk5eWxatUqDh8+TEpKCg0NDWZMamoqRUVF5Ofnk5+fT1FREWlpaebxhoYGRowYQVVVFatWrSIvL49ly5YxadIk914QYDHO4GdeV1ZWYrPZGMh1+Fr82ro5Iq3C4uff1k0QaTX1Rh0f1P0fFRUVhISEtMo9jn1WXHxHDj7WgJO+TkPNUTa/8AAlJSVObbVarVitVpeuERYWxsyZM7ntttuw2+1kZWVx3333AU1VhcjISGbMmMGECROoqKigU6dOLFmyhBtvvBGAvXv3Eh0dzbvvvktycjJbt26lZ8+erF27lsTERADWrl1LUlISX3zxBXFxcbz33nukpKRQUlKC3W4HIC8vj7Fjx1JeXu7W+65Kg4iIiBuio6PNrgCbzcb06dN/8ZyGhgby8vKoqqoiKSmJ4uJiysrKGDp0qBljtVoZMGAAq1evBqCwsJC6ujqnGLvdTnx8vBmzZs0abDabmTAA9O3bF5vN5hQTHx9vJgwAycnJ1NTUUFhY6NZr1+wJERHxDi00e+JElYaf8vnnn5OUlMTRo0dp3749y5cvp2fPnuYHemRkpFN8ZGQku3btAqCsrAx/f39CQ0ObxZSVlZkxERERze4bERHhFHP8fUJDQ/H39zdjXKWkQUREvEcLdMgfG9joiri4OIqKijh48CDLli1jzJgxrFy50jxusTgPrzQMo9m+4x0fc6L4k4lxhbonREREWom/vz8XXHABffr0Yfr06Vx66aU888wzREVFATT7pl9eXm5WBaKioqitrcXhcPxszL59+5rdd//+/U4xx9/H4XBQV1fXrALxS5Q0iIiIVzj27AlPNk8ZhkFNTQ0xMTFERUWxYsUK81htbS0rV66kX79+ACQkJODn5+cUU1payqZNm8yYpKQkKioqWL9+vRmzbt06KioqnGI2bdpEaWmpGVNQUIDVaiUhIcGt9qt7QkREvMMpXhHygQceYPjw4URHR3Po0CHy8vL48MMPyc/Px2KxkJWVRU5ODrGxscTGxpKTk0NQUBCpqakA2Gw2xo0bx6RJk+jYsSNhYWFkZ2fTq1cvBg8eDECPHj0YNmwY6enpzJ8/H4Dx48eTkpJCXFwcAEOHDqVnz56kpaUxc+ZMDhw4QHZ2Nunp6W7PWFHSICIi0gr27dtHWloapaWl2Gw2LrnkEvLz8xkyZAgAkydPprq6moyMDBwOB4mJiRQUFNChQwfzGnPmzMHX15fRo0dTXV3NoEGDWLRoET4+PmbM0qVLyczMNGdZjBo1itzcXPO4j48P77zzDhkZGfTv35/AwEBSU1N5+umn3X5NWqdB5DSndRrkbHYq12nodXsOPv4erNNQe5TPX3qgVdt6ulOlQUREvIMeWOUxDYQUERERl6jSICIiXsHTGRAtMXviTKekQUREvIO6JzympEFERLyDkgaPaUyDiIiIuESVBhER8Qoa0+A5JQ0iIuId1D3hMXVPiIiIiEtUaRAREa9gMQwsHiyC7Mm5ZwslDSIi4h3UPeExdU+IiIiIS1RpEBERr6DZE55T0iAiIt5B3RMeU/eEiIiIuESVBhER8QrqnvCckgYREfEO6p7wmJIGERHxCqo0eE5jGkRERMQlqjSIiIh3UPeEx5Q0iIiI11AXg2fUPSEiIiIuUaVBRES8g2E0bZ6c7+WUNIiIiFfQ7AnPqXtCREREXKJKg4iIeAfNnvCYkgYREfEKlsamzZPzvZ26J0RERMQlqjQIHaPqGDdlL1dccwj/wEa+2Wll9j3RfPl5kBkTfcFRxj1YyiV9D2NpB7u2BTDtjq7s/8bfjOmRUMXY+8q46PIj1NfBV5sDefB33ak9qtxUTp0bM/bSf5iD884/Su3RdmwpbM9fnjyPPTsDfxRl8LusvQxP3U97Wz3bPmnPnx/qyq4dP8SEdqrj9gdK6H1lBUHtG9mzM4C8P3dm1bthZsy5MUe5/YESevY5jK9fI19vC2Lx0+fy2ZqQU/iKxWXqnvCYkgYv195Wz+y/7+Cz1e158HfdOfitL5271VBV6WPGdO5aw+w3vyQ/L4wlT0dSVelDl9gaao9azJgeCVVMW7qTvNwInn/wXOrqLHTvWY2hcp6cYr0SD/H2XyPZ/mkw7XwNxt67h2lLtjN+cDw11U2/17+9o4zf3F7G7OwY9uwM4OaJpeQs3cbt1/Siuqop5t45Ownu0MDU22OpPODLNdcf4P7cr8gcaeWrzcEAPLZwO98UB/Cnm+OoOdqO34zbx2N/2cHvr74Ex36/NnsP5MQ0e8JzbfoV8KOPPmLkyJHY7XYsFgtvvvlmWzbHK42+q5xv9/oz649d2FYUxL49/hSt6kDpLqsZM/ZPZaz/dwgvP2Hnq01BlO22sv5fIVR898MfxQlT9/Lmy+G8nhvJru0B7C22suqdc6irVZVBTq0Hx8Sx4o1wdu0IpHhrELOzY4g8r5bYXke+jzD4zbh95OXa+W9+GLu2BzFrUgzWgEauue478zo9Lj/MW4si2P5pe8pKAvh/z9mpqvThgvim64SE1nFuTA2vPd+Z4i+C2Pt1AH958jwCghrpemF1G7xy+UXH1mnwZPNybfoXvaqqiksvvZTc3Ny2bIZX6zu0ku2fBjJl/te89tlm/lywjeGpP/zhtFgMfjWokm92Wpn26le89tlmnvnHDpKGVZgxto519Eg4wsHvfJnz1g7yPt3MzGVfcvGvDrfFSxJxEtShAYBDB5sqCFHRNYRF1PHxf37oQqirbcfn6zrQI+GH39nNG9pz9cgDtLfVY7EYDBj5HX7+Bp+t6QBApcOXXTsCGPw/32INbKCdj8G1t5RzoNyXHT/q2hM5m7Rp98Tw4cMZPny4y/E1NTXU1NSYP1dWVrZGs7xK5y61pNz6HX97sRN5z0UQd1k1dz7+DXW1Ft5/I4xzwusJat/IjXeXs2hGFC9Ps9PnmkoefulrJv/v+Xy+tj2du9YCkHbPPhY8buerzQEM/l8HT762kwm/jmNvsfUXWiHSWgwmPFTCpvXt2bW96YM8NKIOoFn3geNbPyLP/eHvS87d5/NA7le88dkn1NdZqKlux2PjL6B0d8D3ERYeuCWOR17awfItH2M0Nl3jwTFxVFWq5/d0pO4Jz51Rv9nTp0/n0UcfbetmnFUs7WDHZ4EsfLIzAF9tCqJr3FFG3Pod778RhuX7WtSaf4awfEEnAHZuDqRnnyOMuPU7Pl/bnnbfx7z7SkcKXgszr3PZlYdJvukAC6d3PuWvSwTgrsd3E3PRESb9b49fjLVYDKfq85jsb2hva+BPqXFUHPCl31AHU57/iuzfXsTX24IAg7uf2MXB7/zI/u1F1B5tR/JN+3n0L9v5w6ieHCj3/8l7SRvRQEiPnVEdzvfffz8VFRXmVlJS0tZNOuMdKPdl1/YAp30lO6xEnNtUPag84EN9HT8b892+ptyzWcyXP8SInGp3PrqLvoMdTL75Ir4t++ED3FHeVGEI7VTnFH9Ox3oc3zYd69zlKNeNLWfOvTEU/TeE4q1BLH3mXHZ8HszIW8sBuKz/IX416CBP3n0+WzZ24MtNwfz5wW7UHm3H4P/5DpHp06dzxRVX0KFDByIiIrj++uvZtm2bU4xhGEydOhW73U5gYCADBw5k8+bNTjE1NTVMnDiR8PBwgoODGTVqFHv27HGKcTgcpKWlYbPZsNlspKWlcfDgQaeY3bt3M3LkSIKDgwkPDyczM5PaWvf+Rp9RSYPVaiUkJMRpE89s2RBM9Pk1TvvO7V5D+fdTKevr2rH90yDOO1HMnqaYfSX+fFvqy3nnH/3JGJFTxyDjsV30H+bgvpsvYl+Jc/dYWYmVA+V+9L7yh+5NX79GeiUeYmthewCsgU3TfhqP+2bZ2IBZfbMGfB9z3Awho9GCpZ2+kp6OjnVPeLK5Y+XKldx1112sXbuWFStWUF9fz9ChQ6mqqjJjnnrqKWbPnk1ubi4bNmwgKiqKIUOGcOjQITMmKyuL5cuXk5eXx6pVqzh8+DApKSk0NDSYMampqRQVFZGfn09+fj5FRUWkpaWZxxsaGhgxYgRVVVWsWrWKvLw8li1bxqRJk9x6TWdU94S0vL+92Ik5b+3gpon7+Ojtc4jrfYRrf3eAufeeZ8b83/MRPPDCLjatDebT1e3pc80h+g6p5N7/Pf/7CAtvzIsgLbuMnVsC2bk5kMG/PUD0+TU8kR524huLtJK7ntjFNaMO8Gj6BVRX+ZgVhapKH2pr2gEWlr8cyU13lbL36wC+KbZy092l1Bxtxwd/7whAyVdN+zNzvmbBtGgOOXxJSj5I76sqeeS2WAC2fhzM4QpfsmcXs/QZO7VH2zH85v1ERtew/t/ntNGrl591ip9ymZ+f7/TzwoULiYiIoLCwkKuvvhrDMJg7dy5TpkzhhhtuAGDx4sVERkby6quvMmHCBCoqKnj55ZdZsmQJgwcPBuCVV14hOjqa999/n+TkZLZu3Up+fj5r164lMTERgAULFpCUlMS2bduIi4ujoKCALVu2UFJSgt1uB2DWrFmMHTuWadOmufwlXEmDl9v+aRCPjYvh9/eXcssf91FW4s8LD9v5YHmoGbM638azfzqXm+4u587Hv2HPTiuPp3dj8/r2ZszylzrhF9DIHY/upcM5DezcEsD9N3d3mropciqMTNsPwMzXncvAsybFsOKNcAD+74UorAGN3P3ELtqH1PNFUXse+N2F5hoNDfXteGjshdz2pz08+vIOAoMb2fu1lVn3xLDhg3MAqHT48eCtFzL23j3M+H9f4ONrsHtHII+mX0DxVs2eOJsdPwjfarVitf7y37qKiqZZZ2FhTV+miouLKSsrY+jQoU7XGjBgAKtXr2bChAkUFhZSV1fnFGO324mPj2f16tUkJyezZs0abDabmTAA9O3bF5vNxurVq4mLi2PNmjXEx8ebCQNAcnIyNTU1FBYWcs0117j02ts0aTh8+DBffvml+XNxcTFFRUWEhYXRpUuXNmyZd1n3fgjr3v/5LLMgryMFeR1/Nub13Ehez41syaaJuG1Y1ytciLLwytxzeWXuuT8ZsffrAJ6444KfvcqOz4OZcmucmy2UttJSsyeio6Od9j/yyCNMnTr1Z881DIN77rmHK6+8kvj4eADKysoAiIx0/rsZGRnJrl27zBh/f39CQ0ObxRw7v6ysjIiIiGb3jIiIcIo5/j6hoaH4+/ubMa5o06Rh48aNTtnNPffcA8CYMWNYtGhRG7VKRETOSi00e6KkpMSpnO9KleHuu+/ms88+Y9WqVc2OWSwWp58Nw2i2r1lTjos5UfzJxPySNk0aBg4ciKEVtkRE5Azi7kD8iRMn8tZbb/HRRx9x3nk/jBeLiooCmqoAnTv/MDW9vLzcrApERUVRW1uLw+FwqjaUl5fTr18/M2bfvn3N7rt//36n66xbt87puMPhoK6urlkF4uecUbMnRERETtapnj1hGAZ33303f/vb3/j3v/9NTEyM0/GYmBiioqJYsWKFua+2tpaVK1eaCUFCQgJ+fn5OMaWlpWzatMmMSUpKoqKigvXr15sx69ato6Kiwilm06ZNlJaWmjEFBQVYrVYSEhJcfk0aCCkiIt6h0Wg+j9bd891w11138eqrr/L3v/+dDh06mGMHbDYbgYGBWCwWsrKyyMnJITY2ltjYWHJycggKCiI1NdWMHTduHJMmTaJjx46EhYWRnZ1Nr169zNkUPXr0YNiwYaSnpzN//nwAxo8fT0pKCnFxTWNuhg4dSs+ePUlLS2PmzJkcOHCA7Oxs0tPT3aqaKGkQERHvcIpXhJw3bx7Q1BX/YwsXLmTs2LEATJ48merqajIyMnA4HCQmJlJQUECHDh3M+Dlz5uDr68vo0aOprq5m0KBBLFq0CB+fH55GvHTpUjIzM81ZFqNGjXJ6rpOPjw/vvPMOGRkZ9O/fn8DAQFJTU3n66afdek0W4wweVFBZWYnNZmMg1+Fr0WNo5exk8dMCWXL2qjfq+KDu/6ioqGi1BfuOfVb0G/wovn4Bv3zCT6ivO8rq9x9p1bae7lRpEBERr2DBwymXLdaSM5eSBhER8Q6neEXIs5FmT4iIiIhLVGkQERGv0FIrQnozJQ0iIuIdTvHsibORuidERETEJao0iIiIV7AYBhYPBjN6cu7ZQkmDiIh4h8bvN0/O93LqnhARERGXqNIgIiJeQd0TnlPSICIi3kGzJzympEFERLyDVoT0mMY0iIiIiEtUaRAREa+gFSE9p6RBRES8g7onPKbuCREREXGJKg0iIuIVLI1NmyfnezslDSIi4h3UPeExdU+IiIiIS1RpEBER76DFnTympEFERLyClpH2nLonRERExCWqNIiIiHfQQEiPKWkQERHvYACeTJtUzqCkQUREvIPGNHhOYxpERETEJao0iIiIdzDwcExDi7XkjKWkQUREvIMGQnpM3RMiIiLiElUaRETEOzQCFg/P93JKGkRExCto9oTn1D0hIiIiLlGlQUREvIMGQnpMSYOIiHgHJQ0eU/eEiIhIK/joo48YOXIkdrsdi8XCm2++6XTcMAymTp2K3W4nMDCQgQMHsnnzZqeYmpoaJk6cSHh4OMHBwYwaNYo9e/Y4xTgcDtLS0rDZbNhsNtLS0jh48KBTzO7duxk5ciTBwcGEh4eTmZlJbW2t269JSYOIiHiHY5UGTzY3VFVVcemll5Kbm3vC40899RSzZ88mNzeXDRs2EBUVxZAhQzh06JAZk5WVxfLly8nLy2PVqlUcPnyYlJQUGhoazJjU1FSKiorIz88nPz+foqIi0tLSzOMNDQ2MGDGCqqoqVq1aRV5eHsuWLWPSpEluvoFgMYwzt95SWVmJzWZjINfha/Fr6+aItAqLn39bN0Gk1dQbdXxQ939UVFQQEhLSKvc49lkxKG4Svj7Wk75OfUMN/9o266TaarFYWL58Oddffz3QVGWw2+1kZWVx3333AU1VhcjISGbMmMGECROoqKigU6dOLFmyhBtvvBGAvXv3Eh0dzbvvvktycjJbt26lZ8+erF27lsTERADWrl1LUlISX3zxBXFxcbz33nukpKRQUlKC3W4HIC8vj7Fjx1JeXu7Wa1GlQUREvMKxKZeebNCUhPx4q6mpcbstxcXFlJWVMXToUHOf1WplwIABrF69GoDCwkLq6uqcYux2O/Hx8WbMmjVrsNlsZsIA0LdvX2w2m1NMfHy8mTAAJCcnU1NTQ2FhoVvtVtIgIiLihujoaHP8gM1mY/r06W5fo6ysDIDIyEin/ZGRkeaxsrIy/P39CQ0N/dmYiIiIZtePiIhwijn+PqGhofj7+5sxrtLsCRER8Q4tNHuipKTEqaRvtZ58l4fF4rxEpWEYzfY1b4ZzzIniTybGFao0iIiId2g0PN+AkJAQp+1kkoaoqCiAZt/0y8vLzapAVFQUtbW1OByOn43Zt29fs+vv37/fKeb4+zgcDurq6ppVIH6JkgYREZFTLCYmhqioKFasWGHuq62tZeXKlfTr1w+AhIQE/Pz8nGJKS0vZtGmTGZOUlERFRQXr1683Y9atW0dFRYVTzKZNmygtLTVjCgoKsFqtJCQkuNVudU+IiIh3OMWLOx0+fJgvv/zS/Lm4uJiioiLCwsLo0qULWVlZ5OTkEBsbS2xsLDk5OQQFBZGamgqAzWZj3LhxTJo0iY4dOxIWFkZ2dja9evVi8ODBAPTo0YNhw4aRnp7O/PnzARg/fjwpKSnExcUBMHToUHr27ElaWhozZ87kwIEDZGdnk56e7vYsECUNIiLiJTxMGnDv3I0bN3LNNdeYP99zzz0AjBkzhkWLFjF58mSqq6vJyMjA4XCQmJhIQUEBHTp0MM+ZM2cOvr6+jB49murqagYNGsSiRYvw8fExY5YuXUpmZqY5y2LUqFFOa0P4+PjwzjvvkJGRQf/+/QkMDCQ1NZWnn37a7XdA6zSInOa0ToOczU7lOg2Du2fi286DdRoaa3h/57Ot2tbTnSoNIiLiHfTsCY8paRAREe/QaOBuF0Pz872bZk+IiIiIS1RpEBER72A0Nm2enO/llDSIiIh30JgGjylpEBER76AxDR7TmAYRERFxiSoNIiLiHdQ94TElDSIi4h0MPEwaWqwlZyx1T4iIiIhLVGkQERHvoO4JjylpEBER79DYCHiw1kKj1mlQ94SIiIi4RJUGERHxDuqe8JiSBhER8Q5KGjym7gkRERFxiSoNIiLiHbSMtMeUNIiIiFcwjEYMD55U6cm5ZwslDSIi4h0Mw7NqgcY0aEyDiIiIuEaVBhER8Q6Gh2MaVGlQ0iAiIl6isREsHoxL0JgGdU+IiIiIa1RpEBER76DuCY8paRAREa9gNDZieNA9oSmX6p4QERERF6nSICIi3kHdEx5T0iAiIt6h0QCLkgZPqHtCREREXKJKg4iIeAfDADxZp0GVBiUNIiLiFYxGA8OD7glDSYOSBhER8RJGI55VGjTlUmMaRERExCWqNIiIiFdQ94TnlDSIiIh3UPeEx87opOFY1ldPnUfrdYicziyGpa2bINJq6o064NR8i/f0s6KeupZrzBnqjE4aDh06BMAq3m3jloi0Iv2dEi9w6NAhbDZbq1zb39+fqKgoVpV5/lkRFRWFv79/C7TqzGQxzuBOmsbGRvbu3UuHDh2wWPRt7FSorKwkOjqakpISQkJC2ro5Ii1Kv9+nnmEYHDp0CLvdTrt2rTc2/+jRo9TW1np8HX9/fwICAlqgRWemM7rS0K5dO84777y2boZXCgkJ0R9VOWvp9/vUaq0Kw48FBAR49Yd9S9GUSxEREXGJkgYRERFxiZIGcYvVauWRRx7BarW2dVNEWpx+v0V+3hk9EFJEREROHVUaRERExCVKGkRERMQlShpERETEJUoaRERExCVKGsRlzz//PDExMQQEBJCQkMB//vOftm6SSIv46KOPGDlyJHa7HYvFwptvvtnWTRI5LSlpEJe89tprZGVlMWXKFD755BOuuuoqhg8fzu7du9u6aSIeq6qq4tJLLyU3N7etmyJyWtOUS3FJYmIil19+OfPmzTP39ejRg+uvv57p06e3YctEWpbFYmH58uVcf/31bd0UkdOOKg3yi2prayksLGTo0KFO+4cOHcrq1avbqFUiInKqKWmQX/Ttt9/S0NBAZGSk0/7IyEjKysraqFUiInKqKWkQlx3/+HHDMPRIchERL6KkQX5ReHg4Pj4+zaoK5eXlzaoPIiJy9lLSIL/I39+fhIQEVqxY4bR/xYoV9OvXr41aJSIip5pvWzdAzgz33HMPaWlp9OnTh6SkJF588UV2797NHXfc0dZNE/HY4cOH+fLLL82fi4uLKSoqIiwsjC5durRhy0ROL5pyKS57/vnneeqppygtLSU+Pp45c+Zw9dVXt3WzRDz24Ycfcs011zTbP2bMGBYtWnTqGyRymlLSICIiIi7RmAYRERFxiZIGERERcYmSBhEREXGJkgYRERFxiZIGERERcYmSBhEREXGJkgYRERFxiZIGERERcYmSBhEPTZ06lcsuu8z8eezYsVx//fWnvB1ff/01FouFoqKin4zp1q0bc+fOdfmaixYt4pxzzvG4bRaLhTfffNPj64hI21LSIGelsWPHYrFYsFgs+Pn50b17d7Kzs6mqqmr1ez/zzDMuLz3syge9iMjpQg+skrPWsGHDWLhwIXV1dfznP//h9ttvp6qqinnz5jWLraurw8/Pr0Xua7PZWuQ6IiKnG1Ua5KxltVqJiooiOjqa1NRUbrnlFrNEfqxL4S9/+Qvdu3fHarViGAYVFRWMHz+eiIgIQkJC+PWvf82nn37qdN0nn3ySyMhIOnTowLhx4zh69KjT8eO7JxobG5kxYwYXXHABVquVLl26MG3aNABiYmIA6N27NxaLhYEDB5rnLVy4kB49ehAQEMBFF13E888/73Sf9evX07t3bwICAujTpw+ffPKJ2+/R7Nmz6dWrF8HBwURHR5ORkcHhw4ebxb355ptceOGFBAQEMGTIEEpKSpyOv/322yQkJBAQEED37t159NFHqa+vd7s9InJ6U9IgXiMwMJC6ujrz5y+//JLXX3+dZcuWmd0DI0aMoKysjHfffZfCwkIuv/xyBg0axIEDBwB4/fXXeeSRR5g2bRobN26kc+fOzT7Mj3f//fczY8YMHnroIbZs2cKrr75KZGQk0PTBD/D+++9TWlrK3/72NwAWLFjAlClTmDZtGlu3biUnJ4eHHnqIxYsXA1BVVUVKSgpxcXEUFhYydepUsrOz3X5P2rVrx7PPPsumTZtYvHgx//73v5k8ebJTzJEjR5g2bRqLFy/mv//9L5WVldx0003m8X/+85/87ne/IzMzky1btjB//nwWLVpkJkYichYxRM5CY8aMMa677jrz53Xr1hkdO3Y0Ro8ebRiGYTzyyCOGn5+fUV5ebsb861//MkJCQoyjR486Xev888835s+fbxiGYSQlJRl33HGH0/HExETj0ksvPeG9KysrDavVaixYsOCE7SwuLjYA45NPPnHaHx0dbbz66qtO+x5//HEjKSnJMAzDmD9/vhEWFmZUVVWZx+fNm3fCa/1Y165djTlz5vzk8ddff93o2LGj+fPChQsNwFi7dq25b+vWrQZgrFu3zjAMw7jqqquMnJwcp+ssWbLE6Ny5s/kzYCxfvvwn7ysiZwaNaZCz1j/+8Q/at29PfX09dXV1XHfddTz33HPm8a5du9KpUyfz58LCQg4fPkzHjh2drlNdXc1XX30FwNatW7njjjucjiclJfHBBx+csA1bt26lpqaGQYMGudzu/fv3U1JSwrhx40hPTzf319fXm+Mltm7dyqWXXkpQUJBTO9z1wQcfkJOTw5YtW6isrKS+vp6jR49SVVVFcHAwAL6+vvTp08c856KLLuKcc85h69at/OpXv6KwsJANGzY4VRYaGho4evQoR44ccWqjiJzZlDTIWeuaa65h3rx5+Pn5Ybfbmw10PPaheExjYyOdO3fmww8/bHatk512GBgY6PY5jY2NQFMXRWJiotMxHx8fAAzDOKn2/NiuXbu49tprueOOO3j88ccJCwtj1apVjBs3zqkbB5qmTB7v2L7GxkYeffRRbrjhhmYxAQEBHrdTRE4fShrkrBUcHMwFF1zgcvzll19OWVkZvr6+dOvW7YQxPXr0YO3atdx6663mvrVr1/7kNWNjYwkMDORf//oXt99+e7Pj/v7+QNM382MiIyM599xz2blzJ7fccssJr9uzZ0+WLFlCdXW1mZj8XDtOZOPGjdTX1zNr1izatWsa3vT66683i6uvr2fjxo386le/AmDbtm0cPHiQiy66CGh637Zt2+bWey0iZyYlDSLfGzx4MElJSVx//fXMmDGDuLg49u7dy7vvvsv1119Pnz59+MMf/sCYMWPo06cPV155JUuXLmXz5s107979hNcMCAjgvvvuY/Lkyfj7+9O/f3/279/P5s2bGTduHBEREQQGBpKfn895551HQEAANpuNqVOnkpmZSUhICMOHD6empoaNGzficDi45557SE1NZcqUKYwbN44HH3yQr7/+mqefftqt13v++edTX1/Pc889x8iRI/nvf//LCy+80CzOz8+PiRMn8uyzz+Ln58fdd99N3759zSTi4YcfJiUlhejoaH7729/Srl07PvvsMz7//HOeeOIJ9/8hROS0pdkTIt+zWCy8++67XH311dx2221ceOGF3HTTTXz99dfmbIcbb7yRhx9+mPvuu4+EhAR27drFnXfe+bPXfeihh5g0aRIPP/wwPXr04MYbb6S8vBxoGi/w7LPPMn/+fOx2O9dddx0At99+Oy+99BKLFi2iV69eDBgwgEWLFplTNNu3b8/bb7/Nli1b6N27N1OmTGHGjBluvd7LLruM2bNnM2PGDOLj41m6dCnTp09vFhcUFMR9991HamoqSUlJBAYGkpeXZx5PTk7mH//4BytWrOCKK66gb9++zJ49m65du7rVHhE5/VmMlugcFRERkbOeKg0iIiLiEiUNIiIi4hIlDSIiIuISJQ0iIiLiEiUNIiIi4hIlDSIiIuISJQ0iIiLiEiUNIiIi4hIlDSIiIuISJQ0iIiLiEiUNIiIi4pL/D1NZGWNDoXxXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_svm = SVC(kernel = 'linear', C= 7, gamma=1e-5, class_weight= {0: 1, 1: 2})\n",
    "best_svm.fit(X_train,Y_train)\n",
    "Y_test_pred = best_svm.predict(X_test)\n",
    "print(classification_report(y_true = Y_test, y_pred=best_svm.predict(X_test)))\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_test_pred, labels=best_svm.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_svm.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b96de7e-5e61-488a-87ff-517d69806867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     82620\n",
      "           1       0.35      0.94      0.51      2754\n",
      "\n",
      "    accuracy                           0.94     85374\n",
      "   macro avg       0.67      0.94      0.74     85374\n",
      "weighted avg       0.98      0.94      0.95     85374\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f9c657209d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_svm2 = SVC(kernel = 'linear', C= 7, gamma=1e-5, class_weight='balanced')\n",
    "best_svm2.fit(X_train,Y_train)\n",
    "Y_test_pred = best_svm2.predict(X_test)\n",
    "print(classification_report(y_true = Y_test, y_pred=Y_test_pred))\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_test_pred, labels=best_svm2.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_svm2.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43044dd7-d287-44fa-baf5-0eea53b46cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model-3\n",
    "best_SVM =  SVC(kernel = 'linear', C= 7, gamma=1e-5)\n",
    "X_proc = preprocessor.fit_transform(df_train[[\"age\",\"total_pages_visited\",\"country\",\"new_user\",\"source\"]])\n",
    "best_SVM.fit(X_proc,Y)\n",
    "X_test_comp = preprocessor.transform(df_test)\n",
    "Y_test_comp =best_SVM.predict(X_test_comp)\n",
    "df_test_pred = pd.DataFrame(data=Y_test_comp, columns=['converted'])\n",
    "df_test_pred.to_csv('conversion_data_test_predictions_REDA-model3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce55a5aa-5564-4fe3-a38c-9982388f5633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model-4\n",
    "best_SVM2 =  SVC(kernel = 'linear', C= 7, gamma=1e-5, class_weight='balanced')\n",
    "X_proc = preprocessor.fit_transform(df_train[[\"age\",\"total_pages_visited\",\"country\",\"new_user\",\"source\"]])\n",
    "best_SVM2.fit(X_proc,Y)\n",
    "X_test_comp = preprocessor.transform(df_test)\n",
    "Y_test_comp =best_SVM2.predict(X_test_comp)\n",
    "df_test_pred = pd.DataFrame(data=Y_test_comp, columns=['converted'])\n",
    "df_test_pred.to_csv('conversion_data_test_predictions_REDA-model4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f231bda0-81aa-43c4-a332-bf622a6042d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model-3customweight\n",
    "best_SVM = SVC(kernel = 'linear', C= 7, gamma=1e-5, class_weight= {0: 1, 1: 2})\n",
    "X_proc = preprocessor.fit_transform(df_train[[\"age\",\"total_pages_visited\",\"country\",\"new_user\",\"source\"]])\n",
    "best_SVM.fit(X_proc,Y)\n",
    "X_test_comp = preprocessor.transform(df_test)\n",
    "Y_test_comp =best_SVM.predict(X_test_comp)\n",
    "df_test_pred = pd.DataFrame(data=Y_test_comp, columns=['converted'])\n",
    "df_test_pred.to_csv('conversion_data_test_predictions_REDA-model3customweight.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc821692-95f0-4e7d-a107-9935bf357cb5",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3df1e3e1-37b3-4ce4-a7b5-6b37ff9183c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done.\n",
      "Best hyperparameters :  {'class_weight': {0: 1, 1: 2}, 'max_depth': 20, 'min_samples_split': 7, 'n_estimators': 23}\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestClassifier(random_state=0, criterion='entropy')\n",
    "params = {\n",
    "    'n_estimators': [17,20,23],\n",
    "    'max_depth': [17,20,23],\n",
    "    'min_samples_split': [2,3,5,7],\n",
    "    'class_weight': [{0:1,1:2}, {0:1,1:3}]\n",
    "    \n",
    "}\n",
    "grid_random = GridSearchCV(regressor, param_grid = params, cv = 5, n_jobs=-1, scoring='f1_macro') # cv : the number of folds to be used for CV\n",
    "grid_random.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", grid_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "36ead865-453b-440d-b1b1-1be84297afc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_random = RandomForestClassifier(random_state=0, criterion='entropy', class_weight={0: 1, 1: 2}, max_depth= 20, min_samples_split=7, n_estimators=23, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f945a36-eaa5-4e6b-a5a3-3583eda28630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     82620\n",
      "           1       0.76      0.72      0.74      2754\n",
      "\n",
      "    accuracy                           0.98     85374\n",
      "   macro avg       0.88      0.86      0.87     85374\n",
      "weighted avg       0.98      0.98      0.98     85374\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f9c3e366450>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_random.fit(X_train,Y_train)\n",
    "Y_test_pred = best_random.predict(X_test)\n",
    "print(classification_report(y_true = Y_test, y_pred=best_random.predict(X_test)))\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_test_pred, labels=best_random.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_random.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ffaffed-2237-4cc3-a1a4-21a648b40fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reda/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:166: FutureWarning:\n",
      "\n",
      "`base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m votingClf \u001b[38;5;241m=\u001b[39m VotingClassifier([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf1\u001b[39m\u001b[38;5;124m'\u001b[39m,best_LogR),(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf2\u001b[39m\u001b[38;5;124m'\u001b[39m,best_SVM), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf3\u001b[39m\u001b[38;5;124m'\u001b[39m,best_random)],voting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      8\u001b[0m adaBoostClassifier \u001b[38;5;241m=\u001b[39m AdaBoostClassifier(base_estimator \u001b[38;5;241m=\u001b[39m votingClf)\n\u001b[0;32m----> 9\u001b[0m adaBoostClassifier\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_true \u001b[38;5;241m=\u001b[39m Y_test, y_pred\u001b[38;5;241m=\u001b[39madaBoostClassifier\u001b[38;5;241m.\u001b[39mpredict(X_test)))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_true \u001b[38;5;241m=\u001b[39m Y_test, y_pred\u001b[38;5;241m=\u001b[39madaBoostClassifier\u001b[38;5;241m.\u001b[39mpredict(X_test)))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:162\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    159\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost(\n\u001b[1;32m    163\u001b[0m     iboost, X, y, sample_weight, random_state\n\u001b[1;32m    164\u001b[0m )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:569\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \n\u001b[1;32m    532\u001b[0m \u001b[38;5;124;03mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;124;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:578\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[1;32m    576\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m--> 578\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    580\u001b[0m y_predict_proba \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_voting.py:346\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    344\u001b[0m transformed_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, transformed_y, sample_weight)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_voting.py:81\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[1;32m     82\u001b[0m     delayed(_fit_single_estimator)(\n\u001b[1;32m     83\u001b[0m         clone(clf),\n\u001b[1;32m     84\u001b[0m         X,\n\u001b[1;32m     85\u001b[0m         y,\n\u001b[1;32m     86\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m     87\u001b[0m         message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVoting\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(names[idx], idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(clfs)),\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, clf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(clfs)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clf \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m )\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:35\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m---> 35\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(exc):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:252\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    251\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 252\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:331\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    317\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    321\u001b[0m (\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[0;32m--> 331\u001b[0m ) \u001b[38;5;241m=\u001b[39m libsvm\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    332\u001b[0m     X,\n\u001b[1;32m    333\u001b[0m     y,\n\u001b[1;32m    334\u001b[0m     svm_type\u001b[38;5;241m=\u001b[39msolver_type,\n\u001b[1;32m    335\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_class_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m    338\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[1;32m    339\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC,\n\u001b[1;32m    340\u001b[0m     nu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu,\n\u001b[1;32m    341\u001b[0m     probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability,\n\u001b[1;32m    342\u001b[0m     degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree,\n\u001b[1;32m    343\u001b[0m     shrinking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshrinking,\n\u001b[1;32m    344\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[1;32m    345\u001b[0m     cache_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size,\n\u001b[1;32m    346\u001b[0m     coef0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0,\n\u001b[1;32m    347\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma,\n\u001b[1;32m    348\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon,\n\u001b[1;32m    349\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m    350\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[1;32m    351\u001b[0m )\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_LogR = LogisticRegression(class_weight={0:1,1:2}, penalty='l2', solver= 'liblinear', C=0.1)\n",
    "best_random = RandomForestClassifier(random_state=0, criterion='entropy', class_weight={0: 1, 1: 2}, \n",
    "                                     max_depth= 20, min_samples_split=7, n_estimators=23, bootstrap=True)\n",
    "best_SVM = SVC(kernel = 'linear', C= 7, gamma=1e-5, class_weight= {0: 1, 1: 2}, probability=True)\n",
    "\n",
    "votingClf = VotingClassifier([('clf1',best_LogR),('clf2',best_SVM), ('clf3',best_random)],voting='soft') #\n",
    "\n",
    "adaBoostClassifier = AdaBoostClassifier(base_estimator = votingClf)\n",
    "adaBoostClassifier.fit(X_train, Y_train)\n",
    "print(classification_report(y_true = Y_test, y_pred=adaBoostClassifier.predict(X_test)))\n",
    "print(classification_report(y_true = Y_test, y_pred=adaBoostClassifier.predict(X_test)))\n",
    "# model 1 to amir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb2dc76f-db5c-4143-b95d-415a49f4f994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#votingClf = VotingClassifier([('clf1',model),('clf2',best_ridge), ('clf3',best_random)],voting='hard') #\n",
    "\n",
    "#adaBoostClassifier = AdaBoostClassifier(base_estimator = votingClf)\n",
    "#adaBoostClassifier.fit(X_train, Y_train)\n",
    "#print(classification_report(y_true = Y_test, y_pred=adaBoostClassifier.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3b0f271-3f4a-4189-8da9-0eaca30704c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_comp = preprocessor.transform(df_test)\n",
    "Y_test_comp =adaBoostClassifier.predict(X_test_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e9608ae-87b1-44f8-a190-42f16c227dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_test_pred = pd.DataFrame(data=Y_test_comp, columns=['converted'])\n",
    "df_test_pred.to_csv('conversion_data_test_predictions_REDA-model1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2462b28b-8d21-4c78-8995-e4e6f9dfcc00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'estimator' parameter of AdaBoostClassifier must be an object implementing 'fit' and 'predict' or None. Got StackingClassifier(estimators=[('clf1', LogisticRegression()),\n                               ('clf3',\n                                RandomForestClassifier(class_weight='balanced_subsample',\n                                                       criterion='entropy',\n                                                       max_depth=20,\n                                                       min_samples_split=5,\n                                                       n_estimators=20,\n                                                       random_state=0))]) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m votingClf \u001b[38;5;241m=\u001b[39m StackingClassifier(estimators\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf1\u001b[39m\u001b[38;5;124m'\u001b[39m,model), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf3\u001b[39m\u001b[38;5;124m'\u001b[39m,best_random)]) \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m adaBoostClassifier \u001b[38;5;241m=\u001b[39m AdaBoostClassifier(estimator \u001b[38;5;241m=\u001b[39m votingClf)\n\u001b[0;32m----> 4\u001b[0m adaBoostClassifier\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_true \u001b[38;5;241m=\u001b[39m Y_test, y_pred\u001b[38;5;241m=\u001b[39madaBoostClassifier\u001b[38;5;241m.\u001b[39mpredict(X_test)))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:124\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a boosted classifier/regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m    126\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    127\u001b[0m         X,\n\u001b[1;32m    128\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m         y_numeric\u001b[38;5;241m=\u001b[39mis_regressor(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    134\u001b[0m     )\n\u001b[1;32m    136\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    137\u001b[0m         sample_weight, X, np\u001b[38;5;241m.\u001b[39mfloat64, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    593\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 600\u001b[0m     validate_parameter_constraints(\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameter_constraints,\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    603\u001b[0m         caller_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    604\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:97\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     )\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'estimator' parameter of AdaBoostClassifier must be an object implementing 'fit' and 'predict' or None. Got StackingClassifier(estimators=[('clf1', LogisticRegression()),\n                               ('clf3',\n                                RandomForestClassifier(class_weight='balanced_subsample',\n                                                       criterion='entropy',\n                                                       max_depth=20,\n                                                       min_samples_split=5,\n                                                       n_estimators=20,\n                                                       random_state=0))]) instead."
     ]
    }
   ],
   "source": [
    "votingClf = vClassifier(estimators=[('clf1',model), ('clf3',best_random)]) #\n",
    "\n",
    "adaBoostClassifier = AdaBoostClassifier(estimator = votingClf)\n",
    "adaBoostClassifier.fit(X_train, Y_train)\n",
    "print(classification_report(y_true = Y_test, y_pred=adaBoostClassifier.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df071d0e-ea58-46e1-b4f2-f2ddfede88a0",
   "metadata": {},
   "source": [
    "px.barplot(df, x='source', hue=''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
